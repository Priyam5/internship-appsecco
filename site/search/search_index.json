{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Project Title: Managing a DevSecOps Pipeline with Secure Development and Operations Author: Priyam Singh Mentor: Akash Mahajan , Sunesh Govindaraj , Ayush Priya The report documents the tasks I am working and practicing as a part of my internship at Appsecco to implement DevSecOps pipeline for an application as well as the issues I am facing while working, and how I resolved them.","title":"Introduction"},{"location":"#introduction","text":"Project Title: Managing a DevSecOps Pipeline with Secure Development and Operations Author: Priyam Singh Mentor: Akash Mahajan , Sunesh Govindaraj , Ayush Priya The report documents the tasks I am working and practicing as a part of my internship at Appsecco to implement DevSecOps pipeline for an application as well as the issues I am facing while working, and how I resolved them.","title":"Introduction"},{"location":"Jenkins-installation/","text":"Setting Up Jenkins Objective This section aims to set up the required infrastructure of Jenkins to perform the task and solve the 2nd point of the problem statement under Task 1. What is Jenkins? Jenkins is a self-contained, open-source automation server that can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software. Jenkins can be installed through native system packages, Docker, or even run standalone by any machine with a Java Runtime Environment (JRE) installed. Prerequisite I have setup Ubuntu 18.04 VM for Installing Jenkins . I followed the steps under the Debian/Ubuntu section. I also installed Java 8, by this link specific versions of OpenJDK on Ubuntu 18.04. I decided to go with this documentation as it was concise. Installation steps of Jenkins. STEP 1 - Installing Jenkins First, add the repository key to the system: wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - The system will return OK Next, append the Debian package repository address sudo sh -c 'echo deb https://pkg.jenkins.io/debian-stable binary/ > \\ /etc/apt/sources.list.d/jenkins.list' sudo apt update Finally, install Jenkins and its dependencies: sudo apt install jenkins GPG key error: An LTS (Long-Term Support) release is chosen every 12 weeks from the stream of regular releases as the stable release for that period time. The link gets updated, it gives GPG key error so find the latest link from here under the Debian/Ubuntu section. Certificate verification failed To resolve this pass --no-check-certificate as shown below: wget https://ftp.yz.yamagata-u.sc.jp/pub/misc/jenkins/debian-stable/jenkins_2.235_all.deb --no-check-certificate Again reinstall the Debian file of Jenkins sudo dpkg -i jenkins_2.235.5_all.deb To fix the broken packages run: sudo apt install -f Now again I check the status of jenkins: sudo service jenkins status It shows it is active now. Step 2 \u2014 Starting Jenkins I started Jenkins using systemctl command because systemctl is used to examine and control the state of \u201csystemd\u201d system and service manager: sudo systemctl start jenkins I checked the status of Jenkins service with the below command sudo systemctl status jenkins If it is successfully installed, the beginning of the output will show that the service is active and configured to start for boot. Jenkins is running now. To reach it from a web browser I will adjust the firewall rules to complete the initial setup. Step 3 - Opening the Firewall By default, Jenkins runs on port 8080, opening that port using ufw(Uncomplicated Firewall ): sudo ufw allow 8080 To check the ufw status confirm the new rules: sudo ufw status Note: If the status shows inactive. Then enable the firewall by following the following commands that will OpenSSH sudo ufw allow OpenSSH sudo ufw enable Step 4 \u2014 Setting Up Jenkins Find the IP of your system: ifconfig To complete setup, in the browser I entered http://your_server_ip_or_domain:8080 The Unlock Jenkins screen opens, which will display where the initial password would be stored. In the terminal window, I will use the cat command to display the password: sudo cat /var/lib/jenkins/secrets/initialAdminPassword The 32-character alphanumeric password is displayed in the terminal, paste it into the Administrator password field, then click Continue . Installing suggested plugins I clicked the Install suggested plugins option, which will immediately begin the installation process as shown: Once the installation completes, the screen opens to Create First Admin User , I filled the required details. Click on Save and Continue or select Continue as admin to skip the above step and continue as admin using the initial password used above. The Instance Configuration page will be displayed which will ask to confirm the preferred URL for Jenkins instance. Confirm the appropriate information, click Save and Finish . A confirmation page confirming that Jenkins is Ready! Click Start using Jenkins to visit the main Jenkins dashboard. Here finish the installation of Jenkins in VM. Invalid username or password When I try to login in Jenkins I got the error Invalid username or password . So I changed it by following the steps explained below. Once logged in successfully into Jenkins VM (Virtual Machine). Go to directory Jenkins and open file config.xml . sudo nano /var/lib/Jenkins/config.xml This command will open config.xml file as below: Go to tag and check value, it will be true . You need to update tag value to false as below. Save this file. Once you are done with updating value in the config.xml file. Restart Jenkin's service. sudo service jenkins restart It will show the status active . Now on opening Jenkins URL. It will go to the dashboard direct. No credentials are required. After opening the dashboard Logged in user section will be blank. As it is now Anonymous user . To reset all security options, go to Jenkins -> Manage Jenkins option in left-hand side option lists. Go to the Configure Global Security option Enable Enable Security option. In Security Realm Option Select Jenkins own database option. Unselect Allow users to sign up option under Jenkins own database option. In Authorization section do the following changes : Select Logged-in users can do anything option (Tick). Unselect Allow anonymous read access option under Logged-in users can do anything option. Click Save button. You will be redirected to Create First Admin User page once you click on Save button. Once you fill all the details, click on Create First Admin User button You will be ready with new Admin users to log in again into the Jenkins portal.","title":"Setting Up Jenkins"},{"location":"Jenkins-installation/#setting-up-jenkins","text":"","title":"Setting Up Jenkins"},{"location":"Jenkins-installation/#objective","text":"This section aims to set up the required infrastructure of Jenkins to perform the task and solve the 2nd point of the problem statement under Task 1. What is Jenkins? Jenkins is a self-contained, open-source automation server that can be used to automate all sorts of tasks related to building, testing, and delivering or deploying software. Jenkins can be installed through native system packages, Docker, or even run standalone by any machine with a Java Runtime Environment (JRE) installed.","title":"Objective"},{"location":"Jenkins-installation/#prerequisite","text":"I have setup Ubuntu 18.04 VM for Installing Jenkins . I followed the steps under the Debian/Ubuntu section. I also installed Java 8, by this link specific versions of OpenJDK on Ubuntu 18.04. I decided to go with this documentation as it was concise.","title":"Prerequisite"},{"location":"Jenkins-installation/#installation-steps-of-jenkins","text":"","title":"Installation steps of Jenkins."},{"location":"Jenkins-installation/#step-1-installing-jenkins","text":"First, add the repository key to the system: wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - The system will return OK Next, append the Debian package repository address sudo sh -c 'echo deb https://pkg.jenkins.io/debian-stable binary/ > \\ /etc/apt/sources.list.d/jenkins.list' sudo apt update Finally, install Jenkins and its dependencies: sudo apt install jenkins","title":"STEP 1 - Installing Jenkins"},{"location":"Jenkins-installation/#gpg-key-error","text":"An LTS (Long-Term Support) release is chosen every 12 weeks from the stream of regular releases as the stable release for that period time. The link gets updated, it gives GPG key error so find the latest link from here under the Debian/Ubuntu section.","title":"GPG key error:"},{"location":"Jenkins-installation/#certificate-verification-failed","text":"To resolve this pass --no-check-certificate as shown below: wget https://ftp.yz.yamagata-u.sc.jp/pub/misc/jenkins/debian-stable/jenkins_2.235_all.deb --no-check-certificate Again reinstall the Debian file of Jenkins sudo dpkg -i jenkins_2.235.5_all.deb To fix the broken packages run: sudo apt install -f Now again I check the status of jenkins: sudo service jenkins status It shows it is active now.","title":"Certificate verification failed"},{"location":"Jenkins-installation/#step-2-starting-jenkins","text":"I started Jenkins using systemctl command because systemctl is used to examine and control the state of \u201csystemd\u201d system and service manager: sudo systemctl start jenkins I checked the status of Jenkins service with the below command sudo systemctl status jenkins If it is successfully installed, the beginning of the output will show that the service is active and configured to start for boot. Jenkins is running now. To reach it from a web browser I will adjust the firewall rules to complete the initial setup.","title":"Step 2 \u2014 Starting Jenkins"},{"location":"Jenkins-installation/#step-3-opening-the-firewall","text":"By default, Jenkins runs on port 8080, opening that port using ufw(Uncomplicated Firewall ): sudo ufw allow 8080 To check the ufw status confirm the new rules: sudo ufw status Note: If the status shows inactive. Then enable the firewall by following the following commands that will OpenSSH sudo ufw allow OpenSSH sudo ufw enable","title":"Step 3 - Opening the Firewall"},{"location":"Jenkins-installation/#step-4-setting-up-jenkins","text":"Find the IP of your system: ifconfig To complete setup, in the browser I entered http://your_server_ip_or_domain:8080 The Unlock Jenkins screen opens, which will display where the initial password would be stored. In the terminal window, I will use the cat command to display the password: sudo cat /var/lib/jenkins/secrets/initialAdminPassword The 32-character alphanumeric password is displayed in the terminal, paste it into the Administrator password field, then click Continue . Installing suggested plugins I clicked the Install suggested plugins option, which will immediately begin the installation process as shown: Once the installation completes, the screen opens to Create First Admin User , I filled the required details. Click on Save and Continue or select Continue as admin to skip the above step and continue as admin using the initial password used above. The Instance Configuration page will be displayed which will ask to confirm the preferred URL for Jenkins instance. Confirm the appropriate information, click Save and Finish . A confirmation page confirming that Jenkins is Ready! Click Start using Jenkins to visit the main Jenkins dashboard. Here finish the installation of Jenkins in VM.","title":"Step 4 \u2014 Setting Up Jenkins"},{"location":"Jenkins-installation/#invalid-username-or-password","text":"When I try to login in Jenkins I got the error Invalid username or password . So I changed it by following the steps explained below. Once logged in successfully into Jenkins VM (Virtual Machine). Go to directory Jenkins and open file config.xml . sudo nano /var/lib/Jenkins/config.xml This command will open config.xml file as below: Go to tag and check value, it will be true . You need to update tag value to false as below. Save this file. Once you are done with updating value in the config.xml file. Restart Jenkin's service. sudo service jenkins restart It will show the status active . Now on opening Jenkins URL. It will go to the dashboard direct. No credentials are required. After opening the dashboard Logged in user section will be blank. As it is now Anonymous user . To reset all security options, go to Jenkins -> Manage Jenkins option in left-hand side option lists. Go to the Configure Global Security option Enable Enable Security option. In Security Realm Option Select Jenkins own database option. Unselect Allow users to sign up option under Jenkins own database option. In Authorization section do the following changes : Select Logged-in users can do anything option (Tick). Unselect Allow anonymous read access option under Logged-in users can do anything option. Click Save button. You will be redirected to Create First Admin User page once you click on Save button. Once you fill all the details, click on Create First Admin User button You will be ready with new Admin users to log in again into the Jenkins portal.","title":"Invalid username or password"},{"location":"Ubuntu-server-VM-setup/","text":"Setting Up VM Objective This section aims to set up the required infrastructure to perform the task and solve the 1st point of the problem statement under Task 1. In this section, I will be setting up two VMs: For Jenkins deployment. For the application(SuiteCRM) server. Steps for creating VM I clicked on the NEW icon to create a new machine. Create Virtual Machine window opened, as shown in the picture. Configuration The Name Jenkins-infra. The Type to Linux. Version to Ubuntu (64-bit). Allocated memory size(RAM). Clicked on Create . Create Virtual Hard Disk will open. Allocated the storage. Set the default disk type to VDI(VirtualBox Disk Image) Selected storage on physical hard disk Dynamically allocated . Clicked on Create . VM is ready for Ubuntu 18.04 server installation. To download the server image 18.04 on VirtualBox as it is an LTS (Long Term Support) version which is a desirable feature for a CI pipeline. I followed the official link link . What is LTS? It is a product life cycle management policy in which a stable release of computer software is maintained for a longer period than the standard edition. The term is typically reserved for open-source software. Ubuntu 18.04 server has 5 years of support. Installation steps for Ubuntu Server 18.04 I decided to install the Ubuntu Server 18.04 because my system was not able to support the Desktop Image of Ubuntu 18.04 server. In the VM box, I selected the VM < Jenkins-infra > to install the server and click on Start . Then the Select start-up disk window opened and I clicked on the folder which gave a new screen Optical Disk Selector . I selected the server image and clicked on Choose . Server image is now selected and I clicked on Start . After clicking on Start Jenkins VM starts running. The installer is designed to be easy to use and have sensible defaults so for a first install I have mostly just accepted the defaults for the most straightforward installation. Beginning with installation: Language selection This screen selects the language. The default language for the installed system is selected as English as I did not want to make changes so pressed Enter button. Keyboard configuration By default, the English (US) layout and variant keyboard is selected as here also I do not want to make changes, pressed Enter button. Network Configuration of the network is done from here and I left it as default because I did not want to do any changes. Selected Done and pressed Enter . Configure proxy The proxy configured on this screen is used for accessing the package repository and the snap store both in the installer environment and in the installed system. I did not provide any Proxy address , kept it default and selected Done Mirror The installer will attempt to use GeoIP to lookup an appropriate default package mirror for your location. I kept this too as default and selected Done Guided Storage Configuration I do not have to make any changes to the storage configuration. So I selected Done and pressed the Enter button. Storage Configuration Selected Done and I did not make any changes. Selected continue and pressed Enter to begin the installation. Profile Setup I filled the required details. Selected Done and pressed the Enter button. SSH I Selected the option Install OpenSSH server because by default Ubuntu does not have an SSH server installed. It has only an SSH client installed. It is very common practice for administrators to SSH into the Ubuntu server so later on, I will also have to SSH to connect the two VMs. It is better to install the OpenSSH server here only with one click of a button. Selected Done and pressed the Enter button. Snaps If a network connection is enabled, a selection of snaps that are useful in a server environment is presented and can be selected for installation. After this, selected Done and pressed Enter . Installation logs Once the installation is complete, I selected Reboot pressed Enter button. Similarly, the second VM can be installed. Here, I finished with the installation of Ubuntu 18.04(LTS) server.","title":"Setting Up VM"},{"location":"Ubuntu-server-VM-setup/#setting-up-vm","text":"","title":"Setting Up VM"},{"location":"Ubuntu-server-VM-setup/#objective","text":"This section aims to set up the required infrastructure to perform the task and solve the 1st point of the problem statement under Task 1. In this section, I will be setting up two VMs: For Jenkins deployment. For the application(SuiteCRM) server.","title":"Objective"},{"location":"Ubuntu-server-VM-setup/#steps-for-creating-vm","text":"I clicked on the NEW icon to create a new machine. Create Virtual Machine window opened, as shown in the picture. Configuration The Name Jenkins-infra. The Type to Linux. Version to Ubuntu (64-bit). Allocated memory size(RAM). Clicked on Create . Create Virtual Hard Disk will open. Allocated the storage. Set the default disk type to VDI(VirtualBox Disk Image) Selected storage on physical hard disk Dynamically allocated . Clicked on Create . VM is ready for Ubuntu 18.04 server installation. To download the server image 18.04 on VirtualBox as it is an LTS (Long Term Support) version which is a desirable feature for a CI pipeline. I followed the official link link . What is LTS? It is a product life cycle management policy in which a stable release of computer software is maintained for a longer period than the standard edition. The term is typically reserved for open-source software. Ubuntu 18.04 server has 5 years of support.","title":"Steps for creating VM"},{"location":"Ubuntu-server-VM-setup/#installation-steps-for-ubuntu-server-1804","text":"I decided to install the Ubuntu Server 18.04 because my system was not able to support the Desktop Image of Ubuntu 18.04 server. In the VM box, I selected the VM < Jenkins-infra > to install the server and click on Start . Then the Select start-up disk window opened and I clicked on the folder which gave a new screen Optical Disk Selector . I selected the server image and clicked on Choose . Server image is now selected and I clicked on Start . After clicking on Start Jenkins VM starts running. The installer is designed to be easy to use and have sensible defaults so for a first install I have mostly just accepted the defaults for the most straightforward installation. Beginning with installation: Language selection This screen selects the language. The default language for the installed system is selected as English as I did not want to make changes so pressed Enter button. Keyboard configuration By default, the English (US) layout and variant keyboard is selected as here also I do not want to make changes, pressed Enter button. Network Configuration of the network is done from here and I left it as default because I did not want to do any changes. Selected Done and pressed Enter . Configure proxy The proxy configured on this screen is used for accessing the package repository and the snap store both in the installer environment and in the installed system. I did not provide any Proxy address , kept it default and selected Done Mirror The installer will attempt to use GeoIP to lookup an appropriate default package mirror for your location. I kept this too as default and selected Done Guided Storage Configuration I do not have to make any changes to the storage configuration. So I selected Done and pressed the Enter button. Storage Configuration Selected Done and I did not make any changes. Selected continue and pressed Enter to begin the installation. Profile Setup I filled the required details. Selected Done and pressed the Enter button. SSH I Selected the option Install OpenSSH server because by default Ubuntu does not have an SSH server installed. It has only an SSH client installed. It is very common practice for administrators to SSH into the Ubuntu server so later on, I will also have to SSH to connect the two VMs. It is better to install the OpenSSH server here only with one click of a button. Selected Done and pressed the Enter button. Snaps If a network connection is enabled, a selection of snaps that are useful in a server environment is presented and can be selected for installation. After this, selected Done and pressed Enter . Installation logs Once the installation is complete, I selected Reboot pressed Enter button. Similarly, the second VM can be installed. Here, I finished with the installation of Ubuntu 18.04(LTS) server.","title":"Installation steps for Ubuntu Server 18.04"},{"location":"complete-pipeline-structure/","text":"Complete Pipeline Structure Objective This section aims to define the final structure that is achieved for the pipeline after the various stages integrated into the pipeline as part of the solutions for all the tasks in the problem statement . Pipeline When I completed with all the stages in the pipeline of fetching code from GitHub, building it, static scan, dynamic scan, generating SBOM, code quality analysis, deploying through Docker and doing DAST scan for the SuiteCRM, the final step was to combine all the stages which are being worked so far into a single pipeline as it was done in two separate pipelines just for it do not take a lot of time every time we build the pipeline. Diagrammatic representation Below is the Diagrammatic representation of the final Pipeline: Final Pipeline script The final pipeline script that was the result of combining the two segregated pipelines and removing redundancies is mentioned below and also I copied the required files to the pwd like Dockerfile for docker deployment stage and the python3_phpcs.py script that is required for the stage Code Sniffer for linting : pipeline { agent any stages { stage('git') { steps { git url: 'https://github.com/Priyam5/SuiteCRM.git/' } } stage ('Build') { steps { sh 'composer install' } } stage ('Dependency-Check Analysis'){ steps { dependencyCheck additionalArguments: '', odcInstallation: 'OWASP Dependency-Check Plugin' dependencyCheckPublisher pattern: 'dependency-check-report.xml' sh 'mv dependency-check-report.xml /var/lib/jenkins/workspace/reports' } } stage ('Snyk Security'){ steps { snykSecurity failOnIssues: false, snykInstallation: 'Snyk Security Plugin', snykTokenId: 'snyk-api-token' sh 'mv snyk_monitor_report.json /var/lib/jenkins/workspace/reports' } } stage ('docker deployment') { steps { sh 'docker build -t dockerimage:latest .' sh 'cp /var/lib/jenkins/workspace/config.php $(pwd)' sh 'docker run -v $(pwd):/var/www/html/suitecrm -d --rm --name dockerzap3 -p 1233:80 dockerimage:latest' } } stage ('OWASP ZAP') { steps { sh 'docker pull owasp/zap2docker-stable' sh 'docker run --network=host -v $(pwd)/zap-report:/zap/wrk/ -i owasp/zap2docker-stable zap-baseline.py -t http://192.168.1.2:1233/suitecrm/ -I -r zap_baseline_report.html -l PASS' sh 'docker rm -f dockerzap3' } } stage ('Generating SBOM'){ steps { sh 'composer require --dev cyclonedx/cyclonedx-php-composer' sh 'composer make-bom' sh 'mv bom.xml /var/lib/jenkins/workspace/reports' } } stage ('Code Sniffer for linting'){ steps { sh 'python3 python3_phpcs.py /var/lib/jenkins/workspace/suitecrm-pipeline' } } stage ('Deploying App to production server'){ steps { sh 'echo \"Deploying App to production Server\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"rm -rf suitecrm && mkdir suitecrm\"' sh 'scp -r * production@192.168.1.4:~/suitecrm' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd suitecrm && sudo cp -r * /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"sudo cp -r /home/production/config.php /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd /home/production/html/suitecrm && sudo chmod -R 755 * && sudo chown -R www-data:www-data *\"' } } } }","title":"Complete Pipeline Structure"},{"location":"complete-pipeline-structure/#complete-pipeline-structure","text":"","title":"Complete Pipeline Structure"},{"location":"complete-pipeline-structure/#objective","text":"This section aims to define the final structure that is achieved for the pipeline after the various stages integrated into the pipeline as part of the solutions for all the tasks in the problem statement .","title":"Objective"},{"location":"complete-pipeline-structure/#pipeline","text":"When I completed with all the stages in the pipeline of fetching code from GitHub, building it, static scan, dynamic scan, generating SBOM, code quality analysis, deploying through Docker and doing DAST scan for the SuiteCRM, the final step was to combine all the stages which are being worked so far into a single pipeline as it was done in two separate pipelines just for it do not take a lot of time every time we build the pipeline.","title":"Pipeline"},{"location":"complete-pipeline-structure/#diagrammatic-representation","text":"Below is the Diagrammatic representation of the final Pipeline:","title":"Diagrammatic representation"},{"location":"complete-pipeline-structure/#final-pipeline-script","text":"The final pipeline script that was the result of combining the two segregated pipelines and removing redundancies is mentioned below and also I copied the required files to the pwd like Dockerfile for docker deployment stage and the python3_phpcs.py script that is required for the stage Code Sniffer for linting : pipeline { agent any stages { stage('git') { steps { git url: 'https://github.com/Priyam5/SuiteCRM.git/' } } stage ('Build') { steps { sh 'composer install' } } stage ('Dependency-Check Analysis'){ steps { dependencyCheck additionalArguments: '', odcInstallation: 'OWASP Dependency-Check Plugin' dependencyCheckPublisher pattern: 'dependency-check-report.xml' sh 'mv dependency-check-report.xml /var/lib/jenkins/workspace/reports' } } stage ('Snyk Security'){ steps { snykSecurity failOnIssues: false, snykInstallation: 'Snyk Security Plugin', snykTokenId: 'snyk-api-token' sh 'mv snyk_monitor_report.json /var/lib/jenkins/workspace/reports' } } stage ('docker deployment') { steps { sh 'docker build -t dockerimage:latest .' sh 'cp /var/lib/jenkins/workspace/config.php $(pwd)' sh 'docker run -v $(pwd):/var/www/html/suitecrm -d --rm --name dockerzap3 -p 1233:80 dockerimage:latest' } } stage ('OWASP ZAP') { steps { sh 'docker pull owasp/zap2docker-stable' sh 'docker run --network=host -v $(pwd)/zap-report:/zap/wrk/ -i owasp/zap2docker-stable zap-baseline.py -t http://192.168.1.2:1233/suitecrm/ -I -r zap_baseline_report.html -l PASS' sh 'docker rm -f dockerzap3' } } stage ('Generating SBOM'){ steps { sh 'composer require --dev cyclonedx/cyclonedx-php-composer' sh 'composer make-bom' sh 'mv bom.xml /var/lib/jenkins/workspace/reports' } } stage ('Code Sniffer for linting'){ steps { sh 'python3 python3_phpcs.py /var/lib/jenkins/workspace/suitecrm-pipeline' } } stage ('Deploying App to production server'){ steps { sh 'echo \"Deploying App to production Server\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"rm -rf suitecrm && mkdir suitecrm\"' sh 'scp -r * production@192.168.1.4:~/suitecrm' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd suitecrm && sudo cp -r * /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"sudo cp -r /home/production/config.php /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd /home/production/html/suitecrm && sudo chmod -R 755 * && sudo chown -R www-data:www-data *\"' } } } }","title":"Final Pipeline script"},{"location":"contents/","text":"Table of contents The following is the report/documentation for the Problem Statement stated in next section. The contents of the report are: Introduction Contents Problem Statement Setting Up VM Setting Up Jenkins Setting Up MkDocs for report Setting Up Pipeline Setting Up SuiteCRM Deployment of SuiteCRM Static Analysis of SuiteCRM Dynamic Analysis of SuiteCRM Software Bill of Materials Source Code Quality Analysis Performing DAST of SuiteCRM through Docker Complete Pipeline Structure","title":"Contents"},{"location":"contents/#table-of-contents","text":"The following is the report/documentation for the Problem Statement stated in next section. The contents of the report are: Introduction Contents Problem Statement Setting Up VM Setting Up Jenkins Setting Up MkDocs for report Setting Up Pipeline Setting Up SuiteCRM Deployment of SuiteCRM Static Analysis of SuiteCRM Dynamic Analysis of SuiteCRM Software Bill of Materials Source Code Quality Analysis Performing DAST of SuiteCRM through Docker Complete Pipeline Structure","title":"Table of contents"},{"location":"dast-tools/","text":"Dynamic Analysis of SuiteCRM Objective This section aims to identify suitable tools for SuiteCRM to perform DAST and generate a report to provide a solution to the 8th point of the problem statement under Task 1. DAST DAST or Dynamic Application Security Testing is a black-box testing technique in which the DAST tool interacts with the application being tested in its running state to imitate an attacker. Unlike static analysis, DAST allows for sophisticated scans on the client-side and server-side without needing the source code or the framework the application is built on. They usually require minimal user interactions once configured. In dynamic analysis, tools are used to automate attacks on the application. DAST tools are especially helpful for detecting: input/output validation: (e.g. cross-site scripting and SQL injections); server configuration mistakes; authentication issues; other problems which manifest in real-time or become visible only when a known user logs in. OWASP ZAP Zed Attack Proxy is an open-source tool used to perform dynamic application security testing designed specifically for web applications. ZAP has a desktop interface, APIs for it to be used in an automated fashion, and also a CLI. It imitates an actual user where it interacts with the application to perform various attacks. At its core, ZAP is what is known as a \u201cman-in-the-middle proxy.\u201d It stands between the tester\u2019s browser and the web application so that it can intercept and inspect messages sent between a browser and web application, modify the contents if needed, and then forward those packets on to the destination. It can be used as a stand-alone application, and as a daemon process. ZAP comes with a large number of options to use, for which further details can be found here . ZAP also comes as a Docker image which is more convenient to use especially if one is using the CLI interface. Installation of docker We will start by first updating the existing list of packages. sudo apt update Installation of prerequisite packages so that apt can use packages over HTTPS. sudo apt install apt-transport-https ca-certificates curl software-properties-common Adding GPG key for the official Docker repository curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - Add the Docker repository to APT sources sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\" && sudo apt update To check Docker repository version table and installation candidate, use the below command. apt-cache policy docker-ce Finally, install Docker sudo apt install docker-ce To check the running status of Docker sudo service docker status Configure OWASP ZAP with Docker To understand how ZAP works I first manually perform the steps in the Jenkins VM and then integrated with jenkins pipeline in the next section. For using OWASP ZAP with docker, I have to pull the ZAP image from docker hub . I went through this documentation as a lot of errors are been resolved along with solutions. So firstly I ran ZAP on my Jenkins VM to figure out how it works and test the target URL. And also many flags have been used which can be found here in the official documentation of zap Firstly, I pulled the docker image to be tested. docker pull owasp/zap2docker-stable To run ZAP with CLI interface. docker run -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 -i owasp/zap2docker-stable zap-cli --help -e flag for Docker to inject the environment variables in the container. LC_ALL=C.UTF-8 the environment variable that overrides all the other localization settings (except $LANGUAGE) I ran a quick scan to have a look at how ZAP inputs information. ZAP is running inside a docker container. So I used the IP assigned to docker which can be found by ifconfig command. docker run -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 -i owasp/zap2docker-stable zap-cli quick-scan --start-options '-config api.disablekey=true' --self-contained --spider -l Low http://172.17.0.1:9090 --start-options '-config api.disablekey=true' ZAP also has an API that can be used to interact with it programmatically. Otherwise, ZAP tried (and failed) to connect to the proxy as the API key was not specified. -l Specifies the severity level at which ZAP should log a vulnerability to console or to a report. I ran an active scan docker run --rm -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 --name zap -u zap -p 8090:8080 -d owasp/zap2docker-stable zap.sh -daemon -port 8080 -host 0.0.0.0 -config api.disablekey=true --rm flag to delete the container, automatically to stop it once done. --name for providing the name of the container created. docker exec <CONTAINER NAME/ID> zap-cli open-url <TARGET URL> open-url For starting the daemon for zap to be accessed by the CLI, open-url adds the target URL to the configuration in ZAP-CLI (without this, active-scan option will not start a scan on the target) and then run the scan against SuiteCRM. docker exec <CONTAINER NAME/ID> zap-cli active-scan <TARGET URL> active-scan run's the scan against SuiteCRM. ZAP baseline scan with the docker image docker run -i owasp/zap2docker-stable zap-baseline.py -t \"http://172.17.0.1:9090\" -l INFO -t target URL including the protocol, eg https://www.example.com -l l is for level; minimum level to show: PASS, IGNORE, INFO, WARN or FAIL, use with -s to hide example URLs For saving the report on the Jenkins machine, I needed to mount a volume with Docker. I used the -v flag to mount the present working directory of the host to the /zap/wrk directory of the container docker run -v $(pwd):/zap/wrk/ -i owasp/zap2docker-stable zap-baseline.py -t \"http://192.168.1.2/suitecrmnew\" -r baseline-report.html -l PASS -r file to write the full ZAP HTML report, saves scan output to Jenkins machine. Jenkins Integration Now I will integrate baseline-scan as part of SuiteCRM in the Jenkins-pipeline. I created a separate pipeline for DAST tools as the scan might become too long after combining both SAST and DAST scans also the scan should not be obstructing the business by delaying deployment to production. So in this pipeline, we have to follow the steps of fetching the code, building the pipeline, deploying the application, and then at last DAST scan tools. Starting with the first stage that is fetching the code of SuiteCRM from the GitHub repository. stages { stage('git') { steps { git url: 'https://github.com/Priyam5/SuiteCRM.git/' } } The second stage is for building SuiteCRM, similar to that of SAST pipeline stage ('Build') { steps { sh 'composer install' } } The third stage is for deploying the SuiteCRM application stage ('Deploying App to production server'){ steps { sh 'echo \"Deploying App to production Server\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"rm -rf suitecrm && mkdir suitecrm\"' sh 'scp -r * production@192.168.1.4:~/suitecrm' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd suitecrm && sudo cp -r * /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"sudo cp -r /home/production/config.php /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd /home/production/html/suitecrm && sudo chmod -R 755 * && sudo chown -R www-data:www-data *\"' } } The fourth stage is of OWASP ZAP scan. In this, we will first pull the zap image after that makes a container named zap2 and mention a port to run and the mentioned port should not be used by any other application or it will throw error failed to access the provided URL. Then print the report zap_baseline_report2.html . stage ('OWASP ZAP') { steps { sh 'docker pull owasp/zap2docker-stable' sh 'docker run --rm -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 --name zap2 -u zap -p 8090:8080 -d owasp/zap2docker-stable zap.sh -daemon -port 8080 -host 0.0.0.0 -config api.disablekey=true' sh 'docker run -v $(pwd)/zap-report:/zap/wrk/:rw --rm -i owasp/zap2docker-stable zap-baseline.py -t \"http://192.168.1.4/suitecrm\" -I -r zap_baseline_report2.html -l PASS' sh 'docker rm -f zap2' } } I got the error jenkins-infra@192.168.1.2: Permission denied (public key, password) For this, I ran the command sudo usermod -aG docker jenkins Because Jenkins would require to use sudo when it will run docker commands as it is not part of docker user group on the Jenkins VM. I ran the above command for it, to be able to operate without using sudo. In printing the report I was getting an error as shown below: Permission denied Traceback (most recent call last): File \"/zap/zap-baseline.py\", line 398, in main write_report(base_dir + report_html, zap.core.htmlreport()) File \"/zap/zap_common.py\", line 499, in write_report with open(file_path, mode='wb') as f: IOError: [Errno 13] Permission denied: '/zap/wrk/zap_baseline_report2.html' For this in the Jenkins VM run this command to switch to zap docker run -it owasp/zap2docker-stable Then cat the /etc/passwd to check the user id. It showed this to me zap:x:1000:1000::/home/zap:/bin/bash . After this make a directory zap-report in the workspace of jenkins. Run the below command to give the permissions to zap:x user in docker for the following directory that is created: sudo chown -R 1000:1000 /var/lib/jenkins/workspace/dast-jenkins-pipeline/zap-report/ So the full pipeline looks like this for DAST pipeline which was successful. pipeline { agent any stages { stage('git') { steps { git url: 'https://github.com/Priyam5/SuiteCRM.git/' } } stage ('Build') { steps { sh 'composer install' } } stage ('Deploying App to production server'){ steps { sh 'echo \"Deploying App to production Server\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"rm -rf suitecrm && mkdir suitecrm\"' sh 'scp -r * production@192.168.1.4:~/suitecrm' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd suitecrm && sudo cp -r * /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"sudo cp -r /home/production/config.php /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd /home/production/html/suitecrm && sudo chmod -R 755 * && sudo chown -R www-data:www-data *\"' } } stage ('OWASP ZAP') { steps { sh 'docker pull owasp/zap2docker-stable' sh 'docker rm -f zap2 ; docker run --rm -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 --name zap2 -u zap -p 8090:8080 -d owasp/zap2docker-stable zap.sh -daemon -port 8080 -host 0.0.0.0 -config api.disablekey=true' sh 'docker run -v $(pwd)/zap-report:/zap/wrk/:rw --rm -i owasp/zap2docker-stable zap-baseline.py -t \"http://192.168.1.4/suitecrm\" -I -r zap_baseline_report2.html -l PASS' } } } } The zap-report that was generated can be found here","title":"Dynamic Analysis of SuiteCRM"},{"location":"dast-tools/#dynamic-analysis-of-suitecrm","text":"","title":"Dynamic Analysis of SuiteCRM"},{"location":"dast-tools/#objective","text":"This section aims to identify suitable tools for SuiteCRM to perform DAST and generate a report to provide a solution to the 8th point of the problem statement under Task 1.","title":"Objective"},{"location":"dast-tools/#dast","text":"DAST or Dynamic Application Security Testing is a black-box testing technique in which the DAST tool interacts with the application being tested in its running state to imitate an attacker. Unlike static analysis, DAST allows for sophisticated scans on the client-side and server-side without needing the source code or the framework the application is built on. They usually require minimal user interactions once configured. In dynamic analysis, tools are used to automate attacks on the application. DAST tools are especially helpful for detecting: input/output validation: (e.g. cross-site scripting and SQL injections); server configuration mistakes; authentication issues; other problems which manifest in real-time or become visible only when a known user logs in.","title":"DAST"},{"location":"dast-tools/#owasp-zap","text":"Zed Attack Proxy is an open-source tool used to perform dynamic application security testing designed specifically for web applications. ZAP has a desktop interface, APIs for it to be used in an automated fashion, and also a CLI. It imitates an actual user where it interacts with the application to perform various attacks. At its core, ZAP is what is known as a \u201cman-in-the-middle proxy.\u201d It stands between the tester\u2019s browser and the web application so that it can intercept and inspect messages sent between a browser and web application, modify the contents if needed, and then forward those packets on to the destination. It can be used as a stand-alone application, and as a daemon process. ZAP comes with a large number of options to use, for which further details can be found here . ZAP also comes as a Docker image which is more convenient to use especially if one is using the CLI interface.","title":"OWASP ZAP"},{"location":"dast-tools/#installation-of-docker","text":"We will start by first updating the existing list of packages. sudo apt update Installation of prerequisite packages so that apt can use packages over HTTPS. sudo apt install apt-transport-https ca-certificates curl software-properties-common Adding GPG key for the official Docker repository curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - Add the Docker repository to APT sources sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\" && sudo apt update To check Docker repository version table and installation candidate, use the below command. apt-cache policy docker-ce Finally, install Docker sudo apt install docker-ce To check the running status of Docker sudo service docker status","title":"Installation of docker"},{"location":"dast-tools/#configure-owasp-zap-with-docker","text":"To understand how ZAP works I first manually perform the steps in the Jenkins VM and then integrated with jenkins pipeline in the next section. For using OWASP ZAP with docker, I have to pull the ZAP image from docker hub . I went through this documentation as a lot of errors are been resolved along with solutions. So firstly I ran ZAP on my Jenkins VM to figure out how it works and test the target URL. And also many flags have been used which can be found here in the official documentation of zap Firstly, I pulled the docker image to be tested. docker pull owasp/zap2docker-stable To run ZAP with CLI interface. docker run -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 -i owasp/zap2docker-stable zap-cli --help -e flag for Docker to inject the environment variables in the container. LC_ALL=C.UTF-8 the environment variable that overrides all the other localization settings (except $LANGUAGE) I ran a quick scan to have a look at how ZAP inputs information. ZAP is running inside a docker container. So I used the IP assigned to docker which can be found by ifconfig command. docker run -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 -i owasp/zap2docker-stable zap-cli quick-scan --start-options '-config api.disablekey=true' --self-contained --spider -l Low http://172.17.0.1:9090 --start-options '-config api.disablekey=true' ZAP also has an API that can be used to interact with it programmatically. Otherwise, ZAP tried (and failed) to connect to the proxy as the API key was not specified. -l Specifies the severity level at which ZAP should log a vulnerability to console or to a report. I ran an active scan docker run --rm -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 --name zap -u zap -p 8090:8080 -d owasp/zap2docker-stable zap.sh -daemon -port 8080 -host 0.0.0.0 -config api.disablekey=true --rm flag to delete the container, automatically to stop it once done. --name for providing the name of the container created. docker exec <CONTAINER NAME/ID> zap-cli open-url <TARGET URL> open-url For starting the daemon for zap to be accessed by the CLI, open-url adds the target URL to the configuration in ZAP-CLI (without this, active-scan option will not start a scan on the target) and then run the scan against SuiteCRM. docker exec <CONTAINER NAME/ID> zap-cli active-scan <TARGET URL> active-scan run's the scan against SuiteCRM. ZAP baseline scan with the docker image docker run -i owasp/zap2docker-stable zap-baseline.py -t \"http://172.17.0.1:9090\" -l INFO -t target URL including the protocol, eg https://www.example.com -l l is for level; minimum level to show: PASS, IGNORE, INFO, WARN or FAIL, use with -s to hide example URLs For saving the report on the Jenkins machine, I needed to mount a volume with Docker. I used the -v flag to mount the present working directory of the host to the /zap/wrk directory of the container docker run -v $(pwd):/zap/wrk/ -i owasp/zap2docker-stable zap-baseline.py -t \"http://192.168.1.2/suitecrmnew\" -r baseline-report.html -l PASS -r file to write the full ZAP HTML report, saves scan output to Jenkins machine.","title":"Configure OWASP ZAP with Docker"},{"location":"dast-tools/#jenkins-integration","text":"Now I will integrate baseline-scan as part of SuiteCRM in the Jenkins-pipeline. I created a separate pipeline for DAST tools as the scan might become too long after combining both SAST and DAST scans also the scan should not be obstructing the business by delaying deployment to production. So in this pipeline, we have to follow the steps of fetching the code, building the pipeline, deploying the application, and then at last DAST scan tools. Starting with the first stage that is fetching the code of SuiteCRM from the GitHub repository. stages { stage('git') { steps { git url: 'https://github.com/Priyam5/SuiteCRM.git/' } } The second stage is for building SuiteCRM, similar to that of SAST pipeline stage ('Build') { steps { sh 'composer install' } } The third stage is for deploying the SuiteCRM application stage ('Deploying App to production server'){ steps { sh 'echo \"Deploying App to production Server\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"rm -rf suitecrm && mkdir suitecrm\"' sh 'scp -r * production@192.168.1.4:~/suitecrm' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd suitecrm && sudo cp -r * /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"sudo cp -r /home/production/config.php /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd /home/production/html/suitecrm && sudo chmod -R 755 * && sudo chown -R www-data:www-data *\"' } } The fourth stage is of OWASP ZAP scan. In this, we will first pull the zap image after that makes a container named zap2 and mention a port to run and the mentioned port should not be used by any other application or it will throw error failed to access the provided URL. Then print the report zap_baseline_report2.html . stage ('OWASP ZAP') { steps { sh 'docker pull owasp/zap2docker-stable' sh 'docker run --rm -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 --name zap2 -u zap -p 8090:8080 -d owasp/zap2docker-stable zap.sh -daemon -port 8080 -host 0.0.0.0 -config api.disablekey=true' sh 'docker run -v $(pwd)/zap-report:/zap/wrk/:rw --rm -i owasp/zap2docker-stable zap-baseline.py -t \"http://192.168.1.4/suitecrm\" -I -r zap_baseline_report2.html -l PASS' sh 'docker rm -f zap2' } } I got the error jenkins-infra@192.168.1.2: Permission denied (public key, password) For this, I ran the command sudo usermod -aG docker jenkins Because Jenkins would require to use sudo when it will run docker commands as it is not part of docker user group on the Jenkins VM. I ran the above command for it, to be able to operate without using sudo. In printing the report I was getting an error as shown below: Permission denied Traceback (most recent call last): File \"/zap/zap-baseline.py\", line 398, in main write_report(base_dir + report_html, zap.core.htmlreport()) File \"/zap/zap_common.py\", line 499, in write_report with open(file_path, mode='wb') as f: IOError: [Errno 13] Permission denied: '/zap/wrk/zap_baseline_report2.html' For this in the Jenkins VM run this command to switch to zap docker run -it owasp/zap2docker-stable Then cat the /etc/passwd to check the user id. It showed this to me zap:x:1000:1000::/home/zap:/bin/bash . After this make a directory zap-report in the workspace of jenkins. Run the below command to give the permissions to zap:x user in docker for the following directory that is created: sudo chown -R 1000:1000 /var/lib/jenkins/workspace/dast-jenkins-pipeline/zap-report/ So the full pipeline looks like this for DAST pipeline which was successful. pipeline { agent any stages { stage('git') { steps { git url: 'https://github.com/Priyam5/SuiteCRM.git/' } } stage ('Build') { steps { sh 'composer install' } } stage ('Deploying App to production server'){ steps { sh 'echo \"Deploying App to production Server\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"rm -rf suitecrm && mkdir suitecrm\"' sh 'scp -r * production@192.168.1.4:~/suitecrm' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd suitecrm && sudo cp -r * /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"sudo cp -r /home/production/config.php /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd /home/production/html/suitecrm && sudo chmod -R 755 * && sudo chown -R www-data:www-data *\"' } } stage ('OWASP ZAP') { steps { sh 'docker pull owasp/zap2docker-stable' sh 'docker rm -f zap2 ; docker run --rm -e LC_ALL=C.UTF-8 -e LANG=C.UTF-8 --name zap2 -u zap -p 8090:8080 -d owasp/zap2docker-stable zap.sh -daemon -port 8080 -host 0.0.0.0 -config api.disablekey=true' sh 'docker run -v $(pwd)/zap-report:/zap/wrk/:rw --rm -i owasp/zap2docker-stable zap-baseline.py -t \"http://192.168.1.4/suitecrm\" -I -r zap_baseline_report2.html -l PASS' } } } } The zap-report that was generated can be found here","title":"Jenkins Integration"},{"location":"deployment-of-suitecrm/","text":"Deployment of SuiteCRM Objective This section aims to set up a basic pipeline in Jenkins to provide a solution to the 1st, 2nd, 5th and 6th points of the problem statement under Task 1. Jenkins pipeline project created I clicked on New Item from the main dashboard which leads me to a different page. I gave suitecrm-pipeline as the project's name and chose Pipeline as the project type amongst all the options present. Next came the project configurations page. Here: Under General section: I gave a brief description of the application being deployed and the purpose of this pipeline. I also checked the GitHub Project option and provided the GitHub URL for the project's repository. This option allowed Jenkins to know where to fetch the project from. Under Build Triggers section: I checked the GitHub hook trigger for GITScm Polling option to allow automated builds based on webhook triggers on GitHub for selected events. Under Pipeline section: For Definition, I chose Pipeline Script option and wrote the pipeline code in the script section. Then, I clicked on save to save the configurations made. Jenkinsfile I have explained about Jenkinsfile in Setting Up Pipeline section. The following are the contents of the Jenkinsfile which executes the pipeline: pipeline { agent any stages { stage('git') { steps { git url: 'https://github.com/Priyam5/SuiteCRM.git/' } } stage ('Build') { steps { sh 'composer install' } } stage ('Deploying App to production server'){ steps { sh 'echo \"Deploying App to production Server\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"rm -rf suitecrm && mkdir suitecrm\"' sh 'scp -r * production@192.168.1.4:~/suitecrm' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd suitecrm && sudo cp -r * /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"sudo cp -r /home/production/config.php /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd /home/production/html/suitecrm && sudo chmod -R 755 * && sudo chown -R www-data:www-data *\"' } } } } StrictHostKeyChecking=no In host key checking, SSH automatically maintains and checks a database containing identification for all hosts it has ever been used with. If this property is set to yes, SSH will never automatically add host keys to the $HOME/.ssh/known_hosts file, and refuses to connect to hosts whose host key has changed. This property forces the user to manually add all new hosts. If this property is set to no, ssh will automatically add new host keys to the user known hosts files. The stages of pipeline git : In this stage git repository of SuiteCRM is cloned. Build: In the build stage, application is built and dependencies are installed using composer in the build stage on the Jenkins VM. This loads all the dependencies that the app (SuiteCRM) requires. Deploying App to production server: In this stage, the files are deployed from Jenkins to production VM and also removes the files of SuiteCRM from production server as it might cause conflict in between the files. Build Stage - Permission denied In the build stage, I was getting an error for permission denied for the folder was not getting deleted and permission denied for regular files not being created. So to solve this I followed this documentation I changed root directory to home directory as the DocumentRoot was set to /var/www/html . It was configured in the following file: /etc/apache2/sites-enabled/000-default.conf . I ran this command in terminal to make the changes: sudo nano /etc/apache2/sites-enabled/000-default.conf I changed it to /home/production/html/suitecrm from /var/www/html Then created a file suitecrm under /home/production/html Made changes in the last path in Jenkinsfile to /home/production/html/suitecrm Click On Save and then build the pipeline, it is successfully built this time. SuiteCRM Web Page When I opened the webpage http://192.168.1.4/suitecrm/install.php there it showed to set the session.save_path . So I changed it from this session.save_path = \"var/www/html/suitecrm/\" to session.save_path = \"tmp/\" by going in the file: sudo nano /etc/php/7.2/apache2/php.ini This was displayed when I opened the webpage again: Component Status Writeable Custom Directory The Custom Directory exists but is not writeable. You may have to change permissions on it (chmod 766) or right-click on it and uncheck the read-only option, depending on your Operating System. Please take the needed steps to make the file writeable. Writable Cache Sub-Directories The files or directories listed below are not writeable or are missing and cannot be created. Depending on your Operating System, correcting this may require you to change permissions on the files or parent directory (chmod 755), or to right-click on the parent directory and uncheck the \u2018read only\u2019 option and apply it to all subfolders. Please fix the following files or directories before proceeding: /home/bro303/public_html/crm/cache/images /home/bro303/public_html/crm/cache/layout /home/bro303/public_html/crm/cache/pdf /home/bro303/public_html/crm/cache/xml /home/bro303/public_html/crm/cache/include/javascript I ran these commands to set the following recommended permissions on SuiteCRM instance: sudo chown -R www-data:www-data . sudo chmod -R 755 . sudo chmod -R 775 cache custom modules themes data upload config_override.php After this, the web page opened for making the configurations of database and Site. Note: I was getting an error of database not connected because every time I build the pipeline, it deletes the older files and creates a new one. Hence, config.php file is missing that has the database credentials. So copy the config.php file when SuiteCRM installed manually to another place and also in SuiteCRM instance. and in the pipeline pass the step to copy the config.php file. After it is successfully done the application will be directly deployed by the pipeline. To open the config page multiple times on the browser, I made the changes in config.php file installer_locked = True to false .","title":"Deployment of SuiteCRM"},{"location":"deployment-of-suitecrm/#deployment-of-suitecrm","text":"","title":"Deployment of SuiteCRM"},{"location":"deployment-of-suitecrm/#objective","text":"This section aims to set up a basic pipeline in Jenkins to provide a solution to the 1st, 2nd, 5th and 6th points of the problem statement under Task 1.","title":"Objective"},{"location":"deployment-of-suitecrm/#jenkins-pipeline-project-created","text":"I clicked on New Item from the main dashboard which leads me to a different page. I gave suitecrm-pipeline as the project's name and chose Pipeline as the project type amongst all the options present. Next came the project configurations page. Here: Under General section: I gave a brief description of the application being deployed and the purpose of this pipeline. I also checked the GitHub Project option and provided the GitHub URL for the project's repository. This option allowed Jenkins to know where to fetch the project from. Under Build Triggers section: I checked the GitHub hook trigger for GITScm Polling option to allow automated builds based on webhook triggers on GitHub for selected events. Under Pipeline section: For Definition, I chose Pipeline Script option and wrote the pipeline code in the script section. Then, I clicked on save to save the configurations made.","title":"Jenkins pipeline project created"},{"location":"deployment-of-suitecrm/#jenkinsfile","text":"I have explained about Jenkinsfile in Setting Up Pipeline section. The following are the contents of the Jenkinsfile which executes the pipeline: pipeline { agent any stages { stage('git') { steps { git url: 'https://github.com/Priyam5/SuiteCRM.git/' } } stage ('Build') { steps { sh 'composer install' } } stage ('Deploying App to production server'){ steps { sh 'echo \"Deploying App to production Server\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"rm -rf suitecrm && mkdir suitecrm\"' sh 'scp -r * production@192.168.1.4:~/suitecrm' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd suitecrm && sudo cp -r * /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"sudo cp -r /home/production/config.php /home/production/html/suitecrm\"' sh 'ssh -o StrictHostKeyChecking=no production@192.168.1.4 \"cd /home/production/html/suitecrm && sudo chmod -R 755 * && sudo chown -R www-data:www-data *\"' } } } } StrictHostKeyChecking=no In host key checking, SSH automatically maintains and checks a database containing identification for all hosts it has ever been used with. If this property is set to yes, SSH will never automatically add host keys to the $HOME/.ssh/known_hosts file, and refuses to connect to hosts whose host key has changed. This property forces the user to manually add all new hosts. If this property is set to no, ssh will automatically add new host keys to the user known hosts files.","title":"Jenkinsfile"},{"location":"deployment-of-suitecrm/#the-stages-of-pipeline","text":"git : In this stage git repository of SuiteCRM is cloned. Build: In the build stage, application is built and dependencies are installed using composer in the build stage on the Jenkins VM. This loads all the dependencies that the app (SuiteCRM) requires. Deploying App to production server: In this stage, the files are deployed from Jenkins to production VM and also removes the files of SuiteCRM from production server as it might cause conflict in between the files.","title":"The stages of pipeline"},{"location":"deployment-of-suitecrm/#build-stage-permission-denied","text":"In the build stage, I was getting an error for permission denied for the folder was not getting deleted and permission denied for regular files not being created. So to solve this I followed this documentation I changed root directory to home directory as the DocumentRoot was set to /var/www/html . It was configured in the following file: /etc/apache2/sites-enabled/000-default.conf . I ran this command in terminal to make the changes: sudo nano /etc/apache2/sites-enabled/000-default.conf I changed it to /home/production/html/suitecrm from /var/www/html Then created a file suitecrm under /home/production/html Made changes in the last path in Jenkinsfile to /home/production/html/suitecrm Click On Save and then build the pipeline, it is successfully built this time.","title":"Build Stage - Permission denied"},{"location":"deployment-of-suitecrm/#suitecrm-web-page","text":"When I opened the webpage http://192.168.1.4/suitecrm/install.php there it showed to set the session.save_path . So I changed it from this session.save_path = \"var/www/html/suitecrm/\" to session.save_path = \"tmp/\" by going in the file: sudo nano /etc/php/7.2/apache2/php.ini This was displayed when I opened the webpage again: Component Status Writeable Custom Directory The Custom Directory exists but is not writeable. You may have to change permissions on it (chmod 766) or right-click on it and uncheck the read-only option, depending on your Operating System. Please take the needed steps to make the file writeable. Writable Cache Sub-Directories The files or directories listed below are not writeable or are missing and cannot be created. Depending on your Operating System, correcting this may require you to change permissions on the files or parent directory (chmod 755), or to right-click on the parent directory and uncheck the \u2018read only\u2019 option and apply it to all subfolders. Please fix the following files or directories before proceeding: /home/bro303/public_html/crm/cache/images /home/bro303/public_html/crm/cache/layout /home/bro303/public_html/crm/cache/pdf /home/bro303/public_html/crm/cache/xml /home/bro303/public_html/crm/cache/include/javascript I ran these commands to set the following recommended permissions on SuiteCRM instance: sudo chown -R www-data:www-data . sudo chmod -R 755 . sudo chmod -R 775 cache custom modules themes data upload config_override.php After this, the web page opened for making the configurations of database and Site. Note: I was getting an error of database not connected because every time I build the pipeline, it deletes the older files and creates a new one. Hence, config.php file is missing that has the database credentials. So copy the config.php file when SuiteCRM installed manually to another place and also in SuiteCRM instance. and in the pipeline pass the step to copy the config.php file. After it is successfully done the application will be directly deployed by the pipeline. To open the config page multiple times on the browser, I made the changes in config.php file installer_locked = True to false .","title":"SuiteCRM Web Page"},{"location":"docker/","text":"Performing DAST of SuiteCRM through Docker Objective This section aims to implement the application SuiteCRM through Docker and deploy it through a pipeline and it's just improvisation of previous section Dynamic Analysis of SuiteCRM (https://intern-appsecco.netlify.app/dast-tools/) as here I will perform DAST of SuiteCRM through container. Solution to the first and second point of the problem statement under Task 2. Docker An open-source project that automates the deployment of software applications inside containers by providing an additional layer of abstraction and automation of OS-level virtualization on Linux. In simple, Docker is a tool that allows developers, sys-admins, etc. to deploy applications in a sandbox (which in docker world we call it containers) to run over the host operating system. For Docker commands follow this link . Before installation, let's talk about a little bit about container, image, and Dockerfile as we will come across these terms further: Container - A container is a running instance of an image. Image - An image is a unit that contains everything ( the code, libraries, environments variables, and configuration files) that our service requires to run. Dockerfile - Just assume it as a blueprint for creating Docker images, it can inherit from other containers, define what software to install and what commands to run. Dockerfile Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession. For more details on Dockerfile, I refer this official link of docker I started with building a dockerfile in which I implemented a PHP image because SuiteCRM is a PHP based application. I copied the image from dockerhub of php Apache Installation I begin with building the Dockerfile firstly with apache installation. Note: got an error unable to prepare context: unable to evaluate symlinks in Dockerfile path: lstat /home/jenkins-infra/docker-files/Dockerfile: no such file or directory . So I renamed the Docker file name as Dockerfile . NOTE: I got an error my apache server was not getting served. I will explain in a little detail: I stopped my container docker stop f9af4fb06f4c and ran again docker run -d --rm --name dockercon -p 1234:80 4c0437bfcded` After the container was build I checked If the port 1234 was open or not by netstat -ntap But there was no such network port 1234 open. * Then I checked the docker logs dockercon It showed Error: No such container: dockercon then I checked docker ps -a which showed the container exited in a minute. * After this I ran the above command of building container without the -d flag which is detached mode means running container in background then it gave the error /bin/sh: 1: Syntax error: Unterminated quoted string . From here I got to know I have missed a quote in my dockerfile in a command which I fixed. Dockerfile which finally worked is # getting base image PHP FROM php:7.4-cli MAINTAINER Priyam Singh <2020priyamsingh@gmail.com> # Executed during the building of the image # Apache installation RUN apt-get update RUN apt-get install -y apache2 # Executed when container created out of image CMD [\"apache2ctl\",\"-D\",\"FOREGROUND\"] EXPOSE 80 SuiteCRM installation through a container Apache started running, but then I decided to use the image php:7.4-apache which have apache built-in and not to separately install it. This is the Dockerfile I am using for now #getting base image PHP FROM php:7.4-apache MAINTAINER Priyam Singh <2020priyamsingh@gmail.com> # Executed during the building of the image RUN apt-get update RUN apt-get install -y libzip-dev zip unzip zlib1g-dev RUN docker-php-ext-install mysqli zip # Copying the SUiteCRM repositories COPY dast-jenkins-pipeline /var/www/html/suitecrm RUN chown -R www-data:www-data /var/www/html/suitecrm # Executed when container created out of image CMD [\"apache2ctl\",\"-D\",\"FOREGROUND\"] EXPOSE 80 I build the image by the command below: docker build -t <name>:latest . I ran the container: docker run -d --rm --name <name of container> -p 1234:80 <docker image name> -d : Detached mode means running container in background. --rm : It removes the container when the base system restart or shutdown. --name : For giving name to container. -p : To define ports. I got the below error on the SuiteCRM install.php page when I went to the URL http://192.168.1.2:1234/suitecrm Warning: require_once(modules/DynamicFields/DynamicField.php): failed to open stream: Permission denied in /var/www/html/suitecrm/data/SugarBean.php on line 45 Fatal error: require_once(): Failed opening required 'modules/DynamicFields/DynamicField.php' (include_path='.:/usr/local/lib/php') in /var/www/html/suitecrm/data/SugarBean.php on line 45 So I changed the permission of SuiteCRM directory within the running container docker exec -it <container name> /bin/bash chown -R www-data:www-data suitecrm Changing permissions took too long so I mounted the directory of SuiteCRM. I installed zip because I got error Zip module was not present in docker I added this command in Dockerfile RUN apt-get install -y libzip-dev zip unzip zlib1g-dev RUN docker-php-ext-install mysqli zip My database was not working so I firstly in /etc/mysql/mysql.conf.d/mysqld.cnf file binded the port 0.0.0.0 to allow all ports. I also allowed the port 3306 the mysql port. Then I ran the below command to change the suitecrm@localhost to suitecrm@% so that user is able to login from anywhere. sudo mysql -u root -p UPDATE mysql.user SET Host='%' WHERE Host='localhost' AND User='suitecrm'; UPDATE mysql.db SET Host='%' WHERE Host='localhost' AND User='suitecrm'; FLUSH PRIVILEGES; I copied the config.php file after the installation of SuiteCRM is complete. To use scp to copy files to the remote server from your computer or copy files from the remote server to your computer, you must have the scp program available in both places (computer and remote server). This documentation will be helpful scp -r config.php jenkins-infra@192.168.1.2:/home/jenkins-infra/docker-files but it gave error bash: scp: command not found bec. openssh not installed in container apt install -y openssh-client openssh-server also install on client means we're saving the file the host/client apt install -y openssh-client DAST scan On VM, run the DAST scan similar to earlier as in the section DevSecOps Dynamic Analysis of SuiteCRM . Just do the changes in the command of URL same to where suitecrm is running inside the docker container docker run -i owasp/zap2docker-stable zap-baseline.py -t \"http://192.168.1.2:1234/suitecrm\" -l INFO An error I was facing of no space on the device so remove the images and stopped containers by using the below commands docker rmi <image image name/ image id> docker rm <docker name/docker id> Integrating into Pipeline For integrating on pipeline I followed these steps: Push the Dockerfile to the GitHub SuiteCRM repository which I forked https://github.com/Priyam5/SuiteCRM.git/ in my GitHub. The Dockerfile is: FROM php:7.4-apache MAINTAINER Priyam Singh <2020priyamsingh@gmail.com> RUN apt-get update RUN apt-get install -y libzip-dev zip unzip zlib1g-dev RUN docker-php-ext-install mysqli zip EXPOSE 80 ENTRYPOINT [\"/usr/sbin/apache2ctl\", \"-D\", \"FOREGROUND\"] In the pipeline add the step of docker deployment and in this stage, we will make an image from the Dockerfile and then container and also mount the directory. The stage is shown below stage ('docker deployment') { steps { sh 'docker build -t dockerimage:latest .' sh 'cp /var/lib/jenkins/workspace/config.php $(pwd)' sh 'docker run -v $(pwd):/var/www/html/suitecrm -d --rm --name dockerzap3 -p 1233:80 dockerimage:latest' } } I was getting an apache error: apache2: Syntax error on line 80 of /etc/apache2/apache2.conf: DefaultRuntimeDir must be a valid directory, absolute or relative to ServerRoot . So in Dockerfile I added entrypoint as below: ENTRYPOINT [\"/usr/sbin/apache2ctl\", \"-D\", \"FOREGROUND\"] When I opened the URL http://192.168.1.2:1233/suitecrm/ . SuiteCRM was not getting deployed and I was getting warnings Warning: sugar_file_put_contents_atomic() : fatal rename failure '/tmp/tempPRdtfq' -> 'cache/modules/Employees/Employeevardefs.php' in /var/www/html/suitecrm/include/utils/sugar_file_utils.php on line 204 Warning: sugar_file_put_contents_atomic() : fatal rename failure '/tmp/tempZ0yMaj' -> 'cache/modules/Users/Uservardefs.php' in /var/www/html/suitecrm/include/utils/sugar_file_utils.php on line 204 Warning: sugar_file_put_contents_atomic() : fatal rename failure '/tmp/tempsEJ08b' -> 'cache/modules/UserPreferences/UserPreferencevardefs.php' in /var/www/html/suitecrm/include/utils/sugar_file_utils.php on line 204 Warning: sugar_file_put_contents_atomic() : fatal rename failure '/tmp/tempaF8Pd5' -> 'cache/modules/Administration/Administrationvardefs.php' in /var/www/html/suitecrm/include/utils/sugar_file_utils.php on line 204 Warning: session_start(): Cannot start session when headers already sent in /var/www/html/suitecrm/include/MVC/SugarApplication.php on line 619 Warning: Cannot modify header information - headers already sent by (output started at /var/www/html/suitecrm/include/utils/sugar_file_utils.php:204) in /var/www/html/suitecrm/include/utils.php on line 3124 Warning: session_destroy(): Trying to destroy uninitialized session in /var/www/html/suitecrm/include/MVC/SugarApplication.php on line 132 So it was coming because some directories of SuiteCRM were not having the appropriate permissions. For that I just ran this command and it started working: sudo chmod -R 755 . sudo chmod -R 775 cache custom modules upload Now we will do the zap scan to the container made: stage ('OWASP ZAP') { steps { sh 'docker pull owasp/zap2docker-stable' sh 'docker run --network=host -v $(pwd)/zap-report:/zap/wrk/ -i owasp/zap2docker-stable zap-baseline.py -t http://192.168.1.2:1233/suitecrm/ -I -r zap_baseline_report.html -l PASS' sh 'docker rm -f dockerzap3' I got error I/O error(5): ZAP failed to access: http://192.168.1.2:1233/suitecrm/ because zap container was not able to scan the provided URL due to which I added the flag --network=host and it worked because normally we have to forward ports from the host machine into a container, but when the containers share the host's network, any network activity happens directly on the host machine - just as it would if the program was running locally on the host instead of inside a container. I also got the error SuiteCRM was not able to print the report /zap/wrk/zap_baseline_report.html . So I gave to the directory zap-report permissions: sudo chown -R jenkins:jenkins zap-report sudo chmod 777 zap-report Here is the report which got generated after the zap scan worked successfully.","title":"Performing DAST of SuiteCRM through Docker"},{"location":"docker/#performing-dast-of-suitecrm-through-docker","text":"","title":"Performing DAST of SuiteCRM through Docker"},{"location":"docker/#objective","text":"This section aims to implement the application SuiteCRM through Docker and deploy it through a pipeline and it's just improvisation of previous section Dynamic Analysis of SuiteCRM (https://intern-appsecco.netlify.app/dast-tools/) as here I will perform DAST of SuiteCRM through container. Solution to the first and second point of the problem statement under Task 2.","title":"Objective"},{"location":"docker/#docker","text":"An open-source project that automates the deployment of software applications inside containers by providing an additional layer of abstraction and automation of OS-level virtualization on Linux. In simple, Docker is a tool that allows developers, sys-admins, etc. to deploy applications in a sandbox (which in docker world we call it containers) to run over the host operating system. For Docker commands follow this link . Before installation, let's talk about a little bit about container, image, and Dockerfile as we will come across these terms further: Container - A container is a running instance of an image. Image - An image is a unit that contains everything ( the code, libraries, environments variables, and configuration files) that our service requires to run. Dockerfile - Just assume it as a blueprint for creating Docker images, it can inherit from other containers, define what software to install and what commands to run.","title":"Docker"},{"location":"docker/#dockerfile","text":"Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession. For more details on Dockerfile, I refer this official link of docker I started with building a dockerfile in which I implemented a PHP image because SuiteCRM is a PHP based application. I copied the image from dockerhub of php","title":"Dockerfile"},{"location":"docker/#apache-installation","text":"I begin with building the Dockerfile firstly with apache installation. Note: got an error unable to prepare context: unable to evaluate symlinks in Dockerfile path: lstat /home/jenkins-infra/docker-files/Dockerfile: no such file or directory . So I renamed the Docker file name as Dockerfile . NOTE: I got an error my apache server was not getting served. I will explain in a little detail: I stopped my container docker stop f9af4fb06f4c and ran again docker run -d --rm --name dockercon -p 1234:80 4c0437bfcded` After the container was build I checked If the port 1234 was open or not by netstat -ntap But there was no such network port 1234 open. * Then I checked the docker logs dockercon It showed Error: No such container: dockercon then I checked docker ps -a which showed the container exited in a minute. * After this I ran the above command of building container without the -d flag which is detached mode means running container in background then it gave the error /bin/sh: 1: Syntax error: Unterminated quoted string . From here I got to know I have missed a quote in my dockerfile in a command which I fixed. Dockerfile which finally worked is # getting base image PHP FROM php:7.4-cli MAINTAINER Priyam Singh <2020priyamsingh@gmail.com> # Executed during the building of the image # Apache installation RUN apt-get update RUN apt-get install -y apache2 # Executed when container created out of image CMD [\"apache2ctl\",\"-D\",\"FOREGROUND\"] EXPOSE 80","title":"Apache Installation"},{"location":"docker/#suitecrm-installation-through-a-container","text":"Apache started running, but then I decided to use the image php:7.4-apache which have apache built-in and not to separately install it. This is the Dockerfile I am using for now #getting base image PHP FROM php:7.4-apache MAINTAINER Priyam Singh <2020priyamsingh@gmail.com> # Executed during the building of the image RUN apt-get update RUN apt-get install -y libzip-dev zip unzip zlib1g-dev RUN docker-php-ext-install mysqli zip # Copying the SUiteCRM repositories COPY dast-jenkins-pipeline /var/www/html/suitecrm RUN chown -R www-data:www-data /var/www/html/suitecrm # Executed when container created out of image CMD [\"apache2ctl\",\"-D\",\"FOREGROUND\"] EXPOSE 80 I build the image by the command below: docker build -t <name>:latest . I ran the container: docker run -d --rm --name <name of container> -p 1234:80 <docker image name> -d : Detached mode means running container in background. --rm : It removes the container when the base system restart or shutdown. --name : For giving name to container. -p : To define ports. I got the below error on the SuiteCRM install.php page when I went to the URL http://192.168.1.2:1234/suitecrm Warning: require_once(modules/DynamicFields/DynamicField.php): failed to open stream: Permission denied in /var/www/html/suitecrm/data/SugarBean.php on line 45 Fatal error: require_once(): Failed opening required 'modules/DynamicFields/DynamicField.php' (include_path='.:/usr/local/lib/php') in /var/www/html/suitecrm/data/SugarBean.php on line 45 So I changed the permission of SuiteCRM directory within the running container docker exec -it <container name> /bin/bash chown -R www-data:www-data suitecrm Changing permissions took too long so I mounted the directory of SuiteCRM. I installed zip because I got error Zip module was not present in docker I added this command in Dockerfile RUN apt-get install -y libzip-dev zip unzip zlib1g-dev RUN docker-php-ext-install mysqli zip My database was not working so I firstly in /etc/mysql/mysql.conf.d/mysqld.cnf file binded the port 0.0.0.0 to allow all ports. I also allowed the port 3306 the mysql port. Then I ran the below command to change the suitecrm@localhost to suitecrm@% so that user is able to login from anywhere. sudo mysql -u root -p UPDATE mysql.user SET Host='%' WHERE Host='localhost' AND User='suitecrm'; UPDATE mysql.db SET Host='%' WHERE Host='localhost' AND User='suitecrm'; FLUSH PRIVILEGES; I copied the config.php file after the installation of SuiteCRM is complete. To use scp to copy files to the remote server from your computer or copy files from the remote server to your computer, you must have the scp program available in both places (computer and remote server). This documentation will be helpful scp -r config.php jenkins-infra@192.168.1.2:/home/jenkins-infra/docker-files but it gave error bash: scp: command not found bec. openssh not installed in container apt install -y openssh-client openssh-server also install on client means we're saving the file the host/client apt install -y openssh-client","title":"SuiteCRM installation through a container"},{"location":"docker/#dast-scan","text":"On VM, run the DAST scan similar to earlier as in the section DevSecOps Dynamic Analysis of SuiteCRM . Just do the changes in the command of URL same to where suitecrm is running inside the docker container docker run -i owasp/zap2docker-stable zap-baseline.py -t \"http://192.168.1.2:1234/suitecrm\" -l INFO An error I was facing of no space on the device so remove the images and stopped containers by using the below commands docker rmi <image image name/ image id> docker rm <docker name/docker id>","title":"DAST scan"},{"location":"docker/#integrating-into-pipeline","text":"For integrating on pipeline I followed these steps: Push the Dockerfile to the GitHub SuiteCRM repository which I forked https://github.com/Priyam5/SuiteCRM.git/ in my GitHub. The Dockerfile is: FROM php:7.4-apache MAINTAINER Priyam Singh <2020priyamsingh@gmail.com> RUN apt-get update RUN apt-get install -y libzip-dev zip unzip zlib1g-dev RUN docker-php-ext-install mysqli zip EXPOSE 80 ENTRYPOINT [\"/usr/sbin/apache2ctl\", \"-D\", \"FOREGROUND\"] In the pipeline add the step of docker deployment and in this stage, we will make an image from the Dockerfile and then container and also mount the directory. The stage is shown below stage ('docker deployment') { steps { sh 'docker build -t dockerimage:latest .' sh 'cp /var/lib/jenkins/workspace/config.php $(pwd)' sh 'docker run -v $(pwd):/var/www/html/suitecrm -d --rm --name dockerzap3 -p 1233:80 dockerimage:latest' } } I was getting an apache error: apache2: Syntax error on line 80 of /etc/apache2/apache2.conf: DefaultRuntimeDir must be a valid directory, absolute or relative to ServerRoot . So in Dockerfile I added entrypoint as below: ENTRYPOINT [\"/usr/sbin/apache2ctl\", \"-D\", \"FOREGROUND\"] When I opened the URL http://192.168.1.2:1233/suitecrm/ . SuiteCRM was not getting deployed and I was getting warnings Warning: sugar_file_put_contents_atomic() : fatal rename failure '/tmp/tempPRdtfq' -> 'cache/modules/Employees/Employeevardefs.php' in /var/www/html/suitecrm/include/utils/sugar_file_utils.php on line 204 Warning: sugar_file_put_contents_atomic() : fatal rename failure '/tmp/tempZ0yMaj' -> 'cache/modules/Users/Uservardefs.php' in /var/www/html/suitecrm/include/utils/sugar_file_utils.php on line 204 Warning: sugar_file_put_contents_atomic() : fatal rename failure '/tmp/tempsEJ08b' -> 'cache/modules/UserPreferences/UserPreferencevardefs.php' in /var/www/html/suitecrm/include/utils/sugar_file_utils.php on line 204 Warning: sugar_file_put_contents_atomic() : fatal rename failure '/tmp/tempaF8Pd5' -> 'cache/modules/Administration/Administrationvardefs.php' in /var/www/html/suitecrm/include/utils/sugar_file_utils.php on line 204 Warning: session_start(): Cannot start session when headers already sent in /var/www/html/suitecrm/include/MVC/SugarApplication.php on line 619 Warning: Cannot modify header information - headers already sent by (output started at /var/www/html/suitecrm/include/utils/sugar_file_utils.php:204) in /var/www/html/suitecrm/include/utils.php on line 3124 Warning: session_destroy(): Trying to destroy uninitialized session in /var/www/html/suitecrm/include/MVC/SugarApplication.php on line 132 So it was coming because some directories of SuiteCRM were not having the appropriate permissions. For that I just ran this command and it started working: sudo chmod -R 755 . sudo chmod -R 775 cache custom modules upload Now we will do the zap scan to the container made: stage ('OWASP ZAP') { steps { sh 'docker pull owasp/zap2docker-stable' sh 'docker run --network=host -v $(pwd)/zap-report:/zap/wrk/ -i owasp/zap2docker-stable zap-baseline.py -t http://192.168.1.2:1233/suitecrm/ -I -r zap_baseline_report.html -l PASS' sh 'docker rm -f dockerzap3' I got error I/O error(5): ZAP failed to access: http://192.168.1.2:1233/suitecrm/ because zap container was not able to scan the provided URL due to which I added the flag --network=host and it worked because normally we have to forward ports from the host machine into a container, but when the containers share the host's network, any network activity happens directly on the host machine - just as it would if the program was running locally on the host instead of inside a container. I also got the error SuiteCRM was not able to print the report /zap/wrk/zap_baseline_report.html . So I gave to the directory zap-report permissions: sudo chown -R jenkins:jenkins zap-report sudo chmod 777 zap-report Here is the report which got generated after the zap scan worked successfully.","title":"Integrating into Pipeline"},{"location":"linting-tool/","text":"Source Code Quality Analysis Objective This section aims to perform a linting check on the source code of SuiteCRM and generate a report to provide a solution to the 10th point of the problem statement under Task 1. Code Linting Linting is the automated checking of source code for programmatic and stylistic errors. This is done by using a linting tool. A lint tool is a basic static code analyzer. Linting is important to reduce errors and improve the overall quality of code. Using lint tools can help accelerate development and reduce costs by finding errors earlier. Linting tools are language-specific and thus, the tool that can be used depends on the application being tested. Nowadays, we have different linters, which provide many types of checks like syntax errors, code standards adherence, potential problems, security checks. Linting tools for SuiteCRM Code Quality Analysis tools are language-specific. So for SuiteCRM which are meant for PHP applications. The tool I used is PHP Code Sniffer (PHPCS) there are many other tools available. PHP Code Sniffer PHP_CodeSniffer is a set of two PHP scripts; the main phpcs script that helps to detect violations of pre-defined coding standards and a second phpcbf script that can automatically correct those violations. PHP_CodeSniffer is an essential development tool that ensures code remains clean and consistent. I followed this GitHub documentation. And I will only go with phpcs as I was only concerned with identifying the linting issues therefore skipped the second script. Code Sniffer for SuiteCRM In the Jenkins VM firstly I installed PHPCS for Code Quality Analysis, I downloaded only the phpcs.phar files for the scanner with the command mentioned below. I also tried to git clone and download the PHP_CodeSniffer source but in this phpcs and phpcbf files were not present separately. curl -OL https://squizlabs.github.io/PHP_CodeSniffer/phpcs.phar I made it executable with chmod and moved it to /usr/local/bin for it to be accessible by all system users. chmod +x phpcs.phar mv phpcs.phar /usr/local/bin/phpcs After this I ran phpcs on the SuiteCRM project directory phpcs /var/lib/jenkins/workspace/suitecrm-pipeline Note: The cursor was getting stuck and there was no output so I ran a single PHP file with the above command and it generated the output table. It was getting stuck due to the issue, out of free memory since phpcs was not able to scan the whole SuiteCRM application directory at once. I used a python script python3_phpcs.py from the report to identify all PHP files present in the SuiteCRM project directory and ran phpcs on the files individually. #!/usr/bin/python3 import os import sys print('[+] Starting scan with PHP Code Sniffer...') try: BASE_PATH = sys.argv[1] except IndexError: print('[-] Path not supplied...') sys.exit(1) paths = [BASE_PATH] php_files = [] print('[+] Scanning directory for PHP files...') while paths != []: base_path = paths.pop() try: with os.scandir(base_path) as entries: for entry in entries: if entry.is_file(): if entry.name.endswith('.php'): php_files.append(os.path.join(base_path, entry.name)) else: paths.append(os.path.join(base_path, entry.name)) except PermissionError: print(f'[-] Could not open {base_path} due to insufficient permission...') print('[+] Scan completed...') print('[+] Running PHPCS on PHP files...') try: for php_file in php_files: print(f'[+] Scanning {php_file}') os.system(f'phpcs {php_file} >> /var/lib/jenkins/workspace/reports/phpcs-report-suitecrm') print(f'[+] {len(php_files)} PHP files scanned...') print('[+] Code Quality Report generated...') except KeyboardInterrupt: print('[-] Exiting...') Jenkins Integration At last, I added a stage in the pipeline to execute the Python script by supplying it with the path of the project directory to scan. stage ('Code Snnifer for linting'){ steps { sh 'python3 python3_phpcs.py /var/lib/jenkins/workspace/suitecrm-pipeline' } } I got an error after the build of pipeline permission denied for not able to access the reports directory so I ran the below command sudo chown -R jenkins:jenkins reports/ The report that was generated of Code Sniffer for SuiteCRM after the pipeline build successfully is here .","title":"Source Code Quality Analysis"},{"location":"linting-tool/#source-code-quality-analysis","text":"","title":"Source Code Quality Analysis"},{"location":"linting-tool/#objective","text":"This section aims to perform a linting check on the source code of SuiteCRM and generate a report to provide a solution to the 10th point of the problem statement under Task 1.","title":"Objective"},{"location":"linting-tool/#code-linting","text":"Linting is the automated checking of source code for programmatic and stylistic errors. This is done by using a linting tool. A lint tool is a basic static code analyzer. Linting is important to reduce errors and improve the overall quality of code. Using lint tools can help accelerate development and reduce costs by finding errors earlier. Linting tools are language-specific and thus, the tool that can be used depends on the application being tested. Nowadays, we have different linters, which provide many types of checks like syntax errors, code standards adherence, potential problems, security checks.","title":"Code Linting"},{"location":"linting-tool/#linting-tools-for-suitecrm","text":"Code Quality Analysis tools are language-specific. So for SuiteCRM which are meant for PHP applications. The tool I used is PHP Code Sniffer (PHPCS) there are many other tools available.","title":"Linting tools for SuiteCRM"},{"location":"linting-tool/#php-code-sniffer","text":"PHP_CodeSniffer is a set of two PHP scripts; the main phpcs script that helps to detect violations of pre-defined coding standards and a second phpcbf script that can automatically correct those violations. PHP_CodeSniffer is an essential development tool that ensures code remains clean and consistent. I followed this GitHub documentation. And I will only go with phpcs as I was only concerned with identifying the linting issues therefore skipped the second script.","title":"PHP Code Sniffer"},{"location":"linting-tool/#code-sniffer-for-suitecrm","text":"In the Jenkins VM firstly I installed PHPCS for Code Quality Analysis, I downloaded only the phpcs.phar files for the scanner with the command mentioned below. I also tried to git clone and download the PHP_CodeSniffer source but in this phpcs and phpcbf files were not present separately. curl -OL https://squizlabs.github.io/PHP_CodeSniffer/phpcs.phar I made it executable with chmod and moved it to /usr/local/bin for it to be accessible by all system users. chmod +x phpcs.phar mv phpcs.phar /usr/local/bin/phpcs After this I ran phpcs on the SuiteCRM project directory phpcs /var/lib/jenkins/workspace/suitecrm-pipeline Note: The cursor was getting stuck and there was no output so I ran a single PHP file with the above command and it generated the output table. It was getting stuck due to the issue, out of free memory since phpcs was not able to scan the whole SuiteCRM application directory at once. I used a python script python3_phpcs.py from the report to identify all PHP files present in the SuiteCRM project directory and ran phpcs on the files individually. #!/usr/bin/python3 import os import sys print('[+] Starting scan with PHP Code Sniffer...') try: BASE_PATH = sys.argv[1] except IndexError: print('[-] Path not supplied...') sys.exit(1) paths = [BASE_PATH] php_files = [] print('[+] Scanning directory for PHP files...') while paths != []: base_path = paths.pop() try: with os.scandir(base_path) as entries: for entry in entries: if entry.is_file(): if entry.name.endswith('.php'): php_files.append(os.path.join(base_path, entry.name)) else: paths.append(os.path.join(base_path, entry.name)) except PermissionError: print(f'[-] Could not open {base_path} due to insufficient permission...') print('[+] Scan completed...') print('[+] Running PHPCS on PHP files...') try: for php_file in php_files: print(f'[+] Scanning {php_file}') os.system(f'phpcs {php_file} >> /var/lib/jenkins/workspace/reports/phpcs-report-suitecrm') print(f'[+] {len(php_files)} PHP files scanned...') print('[+] Code Quality Report generated...') except KeyboardInterrupt: print('[-] Exiting...')","title":"Code Sniffer for SuiteCRM"},{"location":"linting-tool/#jenkins-integration","text":"At last, I added a stage in the pipeline to execute the Python script by supplying it with the path of the project directory to scan. stage ('Code Snnifer for linting'){ steps { sh 'python3 python3_phpcs.py /var/lib/jenkins/workspace/suitecrm-pipeline' } } I got an error after the build of pipeline permission denied for not able to access the reports directory so I ran the below command sudo chown -R jenkins:jenkins reports/ The report that was generated of Code Sniffer for SuiteCRM after the pipeline build successfully is here .","title":"Jenkins Integration"},{"location":"mkdocs-setup-usage/","text":"Setting Up MkDocs for Report Objective This section aims to create documentation in Markdown and use MkDocs to deploy the documentation generated as a static site and solve the 3rd point of the problem statement under Task 1. MkDocs is a fast, simple, and static site generator that is geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. Installing MkDocs MkDocs can be installed from this official site link . I only referred to the 'Installing MkDocs' section under 'Manual Installation'. Selecting a Theme MkDocs allows users to use various themes to customize the style and look of the site. I saw the various themes provided from here . I selected the 'Material' theme because I liked the style of the displayed content. To use this theme with MkDocs, it is required to be installed with pip so, I installed Material theme using the command pip install mkdocs-material ' as mentioned in the official documentation. Getting started with Configuration In the terminal: mkdocs new my-project cd my-project The initial project that has been created in the VS Code: A single configuration file named mkdocs.yml , and a folder named docs that will contain documentation source files. The docs folder just contains a single documentation page, named index.md . MkDocs comes with a built-in dev-server to preview the documentation as we work on it. Start the server in the same directory as the mkdocs.yml configuration file, by running the mkdocs serve command: I opened http://127.0.0.1:8000/ in the browser, and saw the default home page. YAML file mkdocs.yml , is present in the root directory of the project that configures the site structure, site title, pages, themes, etc. It is used to define properties for the site. Now change the configuration file to alter how the documentation is displayed by changing the theme. Edit the mkdocs.yml file. My mkdocs.yml is as shown: site_name: <DevSecOps> nav: - Introduction: 'index.md' - Contents: 'contents.md' - Problem Statement: 'problem-statement.md' - Setup of VMs: 'Ubuntu-server-VM-setup.md' - Setup of Jenkins: 'Jenkins-installation.md' - MkDocs setup for report: 'mkdocs-setup-usage.md' theme: material site_name : Title of the site nav : To add some information about the order, title, and nesting of each page in the navigation header by adding a nav setting. theme : The theme we are using. Pushing Code to GitHub I made a repository on GitHub internship-appsecco and also checked the option's Initialize this repository with a README and private repository and after that select the option Create repository . Now in the terminal, I ran: git init mkdocs build git add . git commit -m \"Initial Commit\" git push -u origin master I can see that the MkDocs files are pushed into GitHub. Building the MkDocs Site To serve the documentation files as a website, I have to build the site. Building the site will convert the documentation in Markdown format as a site with HTML and CSS and store it in a folder named site in the same directory as mkdocs.yml file. I ran the below command to build the site from the parent directory (same as mkdocs.yml ), mkdocs build --clean Deploying on Netlify from Github I deployed the site on Github because every time I make the changes, I just have to push it to GitHub and from there the report will be live on a website. Selected the option Add new site on Netlify . Clicked on Add A New Project A screen will open, select the option 1.Connect to Git provider under Create a new site and select GitHub under Continuous Deployment After this Authorize Netlify. It will start showing all repositories. I Selected the appsecco-internship repository and then in Publish directory column type site/ Click on deploy site . The site will be deployed now and the link will be available on the screen which is used to view our report .","title":"Setting Up MkDocs for report"},{"location":"mkdocs-setup-usage/#setting-up-mkdocs-for-report","text":"","title":"Setting Up MkDocs for Report"},{"location":"mkdocs-setup-usage/#objective","text":"This section aims to create documentation in Markdown and use MkDocs to deploy the documentation generated as a static site and solve the 3rd point of the problem statement under Task 1. MkDocs is a fast, simple, and static site generator that is geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file.","title":"Objective"},{"location":"mkdocs-setup-usage/#installing-mkdocs","text":"MkDocs can be installed from this official site link . I only referred to the 'Installing MkDocs' section under 'Manual Installation'.","title":"Installing MkDocs"},{"location":"mkdocs-setup-usage/#selecting-a-theme","text":"MkDocs allows users to use various themes to customize the style and look of the site. I saw the various themes provided from here . I selected the 'Material' theme because I liked the style of the displayed content. To use this theme with MkDocs, it is required to be installed with pip so, I installed Material theme using the command pip install mkdocs-material ' as mentioned in the official documentation.","title":"Selecting a Theme"},{"location":"mkdocs-setup-usage/#getting-started-with-configuration","text":"In the terminal: mkdocs new my-project cd my-project The initial project that has been created in the VS Code: A single configuration file named mkdocs.yml , and a folder named docs that will contain documentation source files. The docs folder just contains a single documentation page, named index.md . MkDocs comes with a built-in dev-server to preview the documentation as we work on it. Start the server in the same directory as the mkdocs.yml configuration file, by running the mkdocs serve command: I opened http://127.0.0.1:8000/ in the browser, and saw the default home page. YAML file mkdocs.yml , is present in the root directory of the project that configures the site structure, site title, pages, themes, etc. It is used to define properties for the site. Now change the configuration file to alter how the documentation is displayed by changing the theme. Edit the mkdocs.yml file. My mkdocs.yml is as shown: site_name: <DevSecOps> nav: - Introduction: 'index.md' - Contents: 'contents.md' - Problem Statement: 'problem-statement.md' - Setup of VMs: 'Ubuntu-server-VM-setup.md' - Setup of Jenkins: 'Jenkins-installation.md' - MkDocs setup for report: 'mkdocs-setup-usage.md' theme: material site_name : Title of the site nav : To add some information about the order, title, and nesting of each page in the navigation header by adding a nav setting. theme : The theme we are using.","title":"Getting started with Configuration"},{"location":"mkdocs-setup-usage/#pushing-code-to-github","text":"I made a repository on GitHub internship-appsecco and also checked the option's Initialize this repository with a README and private repository and after that select the option Create repository . Now in the terminal, I ran: git init mkdocs build git add . git commit -m \"Initial Commit\" git push -u origin master I can see that the MkDocs files are pushed into GitHub.","title":"Pushing Code to GitHub"},{"location":"mkdocs-setup-usage/#building-the-mkdocs-site","text":"To serve the documentation files as a website, I have to build the site. Building the site will convert the documentation in Markdown format as a site with HTML and CSS and store it in a folder named site in the same directory as mkdocs.yml file. I ran the below command to build the site from the parent directory (same as mkdocs.yml ), mkdocs build --clean","title":"Building the MkDocs Site"},{"location":"mkdocs-setup-usage/#deploying-on-netlify-from-github","text":"I deployed the site on Github because every time I make the changes, I just have to push it to GitHub and from there the report will be live on a website. Selected the option Add new site on Netlify . Clicked on Add A New Project A screen will open, select the option 1.Connect to Git provider under Create a new site and select GitHub under Continuous Deployment After this Authorize Netlify. It will start showing all repositories. I Selected the appsecco-internship repository and then in Publish directory column type site/ Click on deploy site . The site will be deployed now and the link will be available on the screen which is used to view our report .","title":"Deploying on Netlify from Github"},{"location":"problem-statement/","text":"Problem Statement Task 1 Setup the infrastructure, required for the task, on two virtual machines running locally on a laptop. One VM contains the Jenkins and related infrastructure, and the second VM is for deploying SuiteCRM using the pipeline. Setup the infrastructure, of Jenkins for basic pipeline setup. Do document extensively in markdown and deploy the documentation as a MkDocs website. Getting to know Jenkins pipeline. SuiteCRM should get deployed in a server that is the second VM. Deployment of SuiteCRM on production server through jenkins pipeline. Identifying suitable tools for SuiteCRM to perform SAST and generate a report. Identifying suitable tools for SuiteCRM to perform DAST and generate a report. Generate Software Bill of Materials of SuiteCRM for all dependencies. Perform Source Code Quality Analysis for linting errors to improve code quality and generate quality report. Task 2 Bring up a temporary testing environment of SuiteCRM for running DAST tool with Docker. Start and stop the testing container and DAST tool container through jenkins pipeline.","title":"Problem Statement"},{"location":"problem-statement/#problem-statement","text":"","title":"Problem Statement"},{"location":"problem-statement/#task-1","text":"Setup the infrastructure, required for the task, on two virtual machines running locally on a laptop. One VM contains the Jenkins and related infrastructure, and the second VM is for deploying SuiteCRM using the pipeline. Setup the infrastructure, of Jenkins for basic pipeline setup. Do document extensively in markdown and deploy the documentation as a MkDocs website. Getting to know Jenkins pipeline. SuiteCRM should get deployed in a server that is the second VM. Deployment of SuiteCRM on production server through jenkins pipeline. Identifying suitable tools for SuiteCRM to perform SAST and generate a report. Identifying suitable tools for SuiteCRM to perform DAST and generate a report. Generate Software Bill of Materials of SuiteCRM for all dependencies. Perform Source Code Quality Analysis for linting errors to improve code quality and generate quality report.","title":"Task 1"},{"location":"problem-statement/#task-2","text":"Bring up a temporary testing environment of SuiteCRM for running DAST tool with Docker. Start and stop the testing container and DAST tool container through jenkins pipeline.","title":"Task 2"},{"location":"sast-tools/","text":"Static Analysis of SuiteCRM Objective This section aims to identify suitable tools for SuiteCRM to perform SAST and generate a report to provide a solution to the 7th point of the problem statement under Task 1. SAST SAST or Static Application Security Testing is a process that analyses a project's source code, dependencies, and related files for known security vulnerabilities. SAST could also help identify segments of the project's logic which might lead to a security vulnerability. OWASP dependency check As mentioned on OWASP Dependency Check's official site , Dependency-Check is a utility that identifies project dependencies and checks if there are any known, publicly disclosed, vulnerabilities. Install the ODC plugin Go to Manage Jenkins then Manage Plugins and under Available section search for ' OWASP dependency-check ' and install the plugin. After this go to the Global Tool Configuration and under Dependency-Check installations add the Name OWASP Dependency-Check Plugin . Jenkins Integration In jenkinsfile add a stage before the build stage: stage ('Dependency-Check Analysis'){ steps { dependencyCheck additionalArguments: '', odcInstallation: 'OWASP Dependency-Check Plugin' } } After this, I got the report in the Console Output after the pipeline is successfully built. Now to get a copy of the report I added one more step to jenkinsfile under the Dependency-Check Analysis stage, and also moved the report to the reports directory where I will be storing all other reports. dependencyCheckPublisher pattern: 'dependency-check-report.xml' sh 'mv dependency-check-report.xml /var/lib/jenkins/workspace/reports' This will create a dependency-check-report.xml report file in the workspace and I can also see in Jenkins the Dependency-Check Trend that is a graphical representation of vulnerabilities found in the SuiteCRM application and they are in which category that is critical, high, medium, low or unassigned. Here is the report which generated after OWASP Dependency-Check. Note: I was getting this error [DependencyCheck] Unable to find Dependency-Check reports to parse because I was using the latest version 5 of OWASP Dependency-Check Plugin but writing the code according to the v4. The default path for report search was **/dependency-check-report.xml in v4 and has changed to dependency-check-report.xml in v5. Snyk Snyk is an open-source security platform for finding out vulnerabilities in the source code of an application. A platform that helps monitor (open source) projects present on GitHub, Bitbucket, etc. or locally to identify dependencies with known vulnerabilities. It is available as a CLI and as a docker image. I followed the official documentation snyk because all the steps are explained well. Install the Snyk plugin Configure Jenkins settings to install the Snyk Security Scanner plugin: Go to Manage Jenkins > Manage Plugins > Available and search for Snyk Security . Install the plugin. Go to Manage Jenkins > Global Tool Configuration and add a Snyk Installation to have the Snyk CLI available during Jenkins builds. From the Snyk app, retrieve Snyk API token: From Snyk account, navigate to Settings > General . Copy the key Go to Manage Jenkins > Manage Credentials > System and add a Snyk API Token to allow the Snyk Security Scanner to identify with Snyk. Specify a credential ID value in the ID field (i.e. snyk-api-token ). Use these values: Kind - Snyk API token Scope - Global Token - Snyk API token(key) as retrieved from Snyk account ID - Enter a name for the token Description - optional free text Jenkins integration From within Jenkins, generate a Snyk Security pipeline: Navigate to the pipeline project and click Pipeline Syntax. From the Sample Step dropdown, select snykSecurity: Invoke Snyk Security task . Configure the security task as follows when issues are found select Let the build continue display vulnerabilities and details, but allow the build to continue and provide the snyk token. Clicked on Generate Pipeline Script . The pipeline syntax is generated and displayed. In the pipeline add the step under the Snyk Security stage before build stage and I also moved the report to the reports directory where I will be storing all other reports: stage ('Snyk Security'){ steps { snykSecurity failOnIssues: false, snykInstallation: 'Snyk Security Plugin', snykTokenId: 'snyk-api-token' sh 'mv snyk_monitor_report.json /var/lib/jenkins/workspace/reports' } } Build the pipeline and the report is generated.","title":"Static Analysis of SuiteCRM"},{"location":"sast-tools/#static-analysis-of-suitecrm","text":"","title":"Static Analysis of SuiteCRM"},{"location":"sast-tools/#objective","text":"This section aims to identify suitable tools for SuiteCRM to perform SAST and generate a report to provide a solution to the 7th point of the problem statement under Task 1.","title":"Objective"},{"location":"sast-tools/#sast","text":"SAST or Static Application Security Testing is a process that analyses a project's source code, dependencies, and related files for known security vulnerabilities. SAST could also help identify segments of the project's logic which might lead to a security vulnerability.","title":"SAST"},{"location":"sast-tools/#owasp-dependency-check","text":"As mentioned on OWASP Dependency Check's official site , Dependency-Check is a utility that identifies project dependencies and checks if there are any known, publicly disclosed, vulnerabilities.","title":"OWASP dependency check"},{"location":"sast-tools/#install-the-odc-plugin","text":"Go to Manage Jenkins then Manage Plugins and under Available section search for ' OWASP dependency-check ' and install the plugin. After this go to the Global Tool Configuration and under Dependency-Check installations add the Name OWASP Dependency-Check Plugin .","title":"Install the ODC plugin"},{"location":"sast-tools/#jenkins-integration","text":"In jenkinsfile add a stage before the build stage: stage ('Dependency-Check Analysis'){ steps { dependencyCheck additionalArguments: '', odcInstallation: 'OWASP Dependency-Check Plugin' } } After this, I got the report in the Console Output after the pipeline is successfully built. Now to get a copy of the report I added one more step to jenkinsfile under the Dependency-Check Analysis stage, and also moved the report to the reports directory where I will be storing all other reports. dependencyCheckPublisher pattern: 'dependency-check-report.xml' sh 'mv dependency-check-report.xml /var/lib/jenkins/workspace/reports' This will create a dependency-check-report.xml report file in the workspace and I can also see in Jenkins the Dependency-Check Trend that is a graphical representation of vulnerabilities found in the SuiteCRM application and they are in which category that is critical, high, medium, low or unassigned. Here is the report which generated after OWASP Dependency-Check. Note: I was getting this error [DependencyCheck] Unable to find Dependency-Check reports to parse because I was using the latest version 5 of OWASP Dependency-Check Plugin but writing the code according to the v4. The default path for report search was **/dependency-check-report.xml in v4 and has changed to dependency-check-report.xml in v5.","title":"Jenkins Integration"},{"location":"sast-tools/#snyk","text":"Snyk is an open-source security platform for finding out vulnerabilities in the source code of an application. A platform that helps monitor (open source) projects present on GitHub, Bitbucket, etc. or locally to identify dependencies with known vulnerabilities. It is available as a CLI and as a docker image. I followed the official documentation snyk because all the steps are explained well.","title":"Snyk"},{"location":"sast-tools/#install-the-snyk-plugin","text":"Configure Jenkins settings to install the Snyk Security Scanner plugin: Go to Manage Jenkins > Manage Plugins > Available and search for Snyk Security . Install the plugin. Go to Manage Jenkins > Global Tool Configuration and add a Snyk Installation to have the Snyk CLI available during Jenkins builds. From the Snyk app, retrieve Snyk API token: From Snyk account, navigate to Settings > General . Copy the key Go to Manage Jenkins > Manage Credentials > System and add a Snyk API Token to allow the Snyk Security Scanner to identify with Snyk. Specify a credential ID value in the ID field (i.e. snyk-api-token ). Use these values: Kind - Snyk API token Scope - Global Token - Snyk API token(key) as retrieved from Snyk account ID - Enter a name for the token Description - optional free text","title":"Install the Snyk plugin"},{"location":"sast-tools/#jenkins-integration_1","text":"From within Jenkins, generate a Snyk Security pipeline: Navigate to the pipeline project and click Pipeline Syntax. From the Sample Step dropdown, select snykSecurity: Invoke Snyk Security task . Configure the security task as follows when issues are found select Let the build continue display vulnerabilities and details, but allow the build to continue and provide the snyk token. Clicked on Generate Pipeline Script . The pipeline syntax is generated and displayed. In the pipeline add the step under the Snyk Security stage before build stage and I also moved the report to the reports directory where I will be storing all other reports: stage ('Snyk Security'){ steps { snykSecurity failOnIssues: false, snykInstallation: 'Snyk Security Plugin', snykTokenId: 'snyk-api-token' sh 'mv snyk_monitor_report.json /var/lib/jenkins/workspace/reports' } } Build the pipeline and the report is generated.","title":"Jenkins integration"},{"location":"sbom/","text":"Software Bill of Materials Objective This section aims to generate a Software Bill of Materials for SuiteCRM and generate a report to provide a solution to the 9th point of the problem statement under Task 1. Software Bill of Materials A software bill of materials is a list of all the open-source and third-party components which are present in a codebase. A software BOM also lists the licenses that govern those components, the versions of the components used in the codebase, and their patch status. In this documentation Software Bill of Materials is very well described. CycloneDX CycloneDX is a tool of lightweight software bill of materials (SBOM) specification designed for use in application security contexts and supply chain component analysis. SuiteCRM, like most other applications, is built with various dependencies. So I used CycloneDX to generate the SBOM for SuiteCRM, According to its documentation , it is a tool that creates the SBOM which contains the aggregate of all the dependencies for the application. CycloneDX is available to use a PHP package that can generate SBOMs for PHP applications but also comes in a variety of implementations that can be found here to serve projects which use different stacks such as Auditjs, Python, Maven, .NET, PHP, etc. For my application, I went with the PHP package as SuiteCRM utilizes PHP Composer. Generating SBOM for SuiteCRM For generating SBOM I started with installing CycloneDX plugin for php-composer by following the official documentation . I used the below command for installation in my Jenkins VM. composer require --dev cyclonedx/cyclonedx-php-composer Then I ran CycloneDX, with the command mentioned below, to check the output and figure out the structure of the SBOM generated as an XML file: composer make-bom Jenkins integration of SBOM I added a stage in the Jenkins Pipeline where I commented out SAST analysis steps just to avoid the pipeline do not take much time and added a stage for Generating SBOM . I also moved the report to the reports directory where I will be storing all other reports: stage ('Generating SBOM'){ steps { sh 'composer require --dev cyclonedx/cyclonedx-php-composer' sh 'composer make-bom' sh 'mv bom.xml /var/lib/jenkins/workspace/reports' } } SBOM for SuiteSRM CycloneDX generated an XML format comprehensive report for SuiteCRM. In this report, it mentioned the components type, group, name, version, description, licenses, Persistent URL(PURL). The report which got generated is here .","title":"Software Bill of Materials"},{"location":"sbom/#software-bill-of-materials","text":"","title":"Software Bill of Materials"},{"location":"sbom/#objective","text":"This section aims to generate a Software Bill of Materials for SuiteCRM and generate a report to provide a solution to the 9th point of the problem statement under Task 1.","title":"Objective"},{"location":"sbom/#software-bill-of-materials_1","text":"A software bill of materials is a list of all the open-source and third-party components which are present in a codebase. A software BOM also lists the licenses that govern those components, the versions of the components used in the codebase, and their patch status. In this documentation Software Bill of Materials is very well described.","title":"Software Bill of Materials"},{"location":"sbom/#cyclonedx","text":"CycloneDX is a tool of lightweight software bill of materials (SBOM) specification designed for use in application security contexts and supply chain component analysis. SuiteCRM, like most other applications, is built with various dependencies. So I used CycloneDX to generate the SBOM for SuiteCRM, According to its documentation , it is a tool that creates the SBOM which contains the aggregate of all the dependencies for the application. CycloneDX is available to use a PHP package that can generate SBOMs for PHP applications but also comes in a variety of implementations that can be found here to serve projects which use different stacks such as Auditjs, Python, Maven, .NET, PHP, etc. For my application, I went with the PHP package as SuiteCRM utilizes PHP Composer.","title":"CycloneDX"},{"location":"sbom/#generating-sbom-for-suitecrm","text":"For generating SBOM I started with installing CycloneDX plugin for php-composer by following the official documentation . I used the below command for installation in my Jenkins VM. composer require --dev cyclonedx/cyclonedx-php-composer Then I ran CycloneDX, with the command mentioned below, to check the output and figure out the structure of the SBOM generated as an XML file: composer make-bom","title":"Generating SBOM for SuiteCRM"},{"location":"sbom/#jenkins-integration-of-sbom","text":"I added a stage in the Jenkins Pipeline where I commented out SAST analysis steps just to avoid the pipeline do not take much time and added a stage for Generating SBOM . I also moved the report to the reports directory where I will be storing all other reports: stage ('Generating SBOM'){ steps { sh 'composer require --dev cyclonedx/cyclonedx-php-composer' sh 'composer make-bom' sh 'mv bom.xml /var/lib/jenkins/workspace/reports' } }","title":"Jenkins integration of SBOM"},{"location":"sbom/#sbom-for-suitesrm","text":"CycloneDX generated an XML format comprehensive report for SuiteCRM. In this report, it mentioned the components type, group, name, version, description, licenses, Persistent URL(PURL). The report which got generated is here .","title":"SBOM for SuiteSRM"},{"location":"setting-up-pipeline/","text":"Setting up pipeline Objective This section aims to set up a basic pipeline in Jenkins to perform the task and solve the 4th point of the problem statement under Task 1. Why Pipeline? Jenkins is, fundamentally, an automation engine that supports several automation patterns. Pipeline adds a powerful set of automation tools onto Jenkins, supporting use cases that span from simple continuous integration to comprehensive CD pipelines. By modeling a series of related tasks, Pipeline has many features: Code: Pipelines are implemented in code and typically checked into source control, giving teams the ability to edit, review, and iterate upon their delivery pipeline. Durable: Pipelines can survive both planned and unplanned restarts of the Jenkins master. Pausable: Pipelines can optionally stop and wait for human input or approval before continuing the Pipeline run. Versatile: Pipelines support complex real-world CD requirements, including the ability to fork/join, loop, and perform work in parallel. Extensible: The Pipeline plugin supports custom extensions to its DSL(Domain Specific Language) and multiple options for integration with other plugins. Jenkins pipeline Project I set up Jenkins as mentioned in the Setup of Jenkins section. For building a pipeline for Maven project I followed these steps and also downloaded Maven in my Jenkins VM for all the repositories related to it are present in the system: Click on the New Item from the main dashboard which leads to a different page. Filled the project name as Jenkins-Maven and choose Maven Project as the project type as it was a Maven based project. Next come's the project configurations page. Here: Under General section: I gave a description of the application being deployed and the purpose of this pipeline. Under the Source Code Management option I checked the Git option and provided the GitHub URL for the project's repository. This option allow's Jenkins to know where to fetch the project from. Under Build Triggers section: I checked the Build whenever a SNAPSHOT dependency is built option to allow automated builds. I clicked on save to save the configurations. Jenkinsfile Jenkinsfile is defined as a utility where the actions that are to be performed on the build can be written in a syntactical format in a file. I followed this official documentation , as it has a simple format with examples. The following are the contents of the Jenkinsfile which executes the pipeline: pipeline { agent any stages { stage ('Compile Stage') { steps { withMaven(maven : 'maven_3_5_0') { sh 'mvn clean compile' } } } stage ('Testing Stage') { steps { withMaven(maven : 'maven_3_5_0') { sh 'mvn test' } } } stage ('Deployment Stage') { steps { withMaven(maven : 'maven_3_5_0') { sh 'mvn deploy' } } } } } The pipeline block constitutes the entire definition of the pipeline. The agent keyword is used to choose the way the Jenkins instance(s) are used to run the pipeline. The any keyword defines that Jenkins should allocate any available agent (an instance of Jenkins/a slave/the master instance) to execute the pipeline. A more thorough explanation can be found here . The stages block houses all the stages that will comprise the various operations to be performed during the execution of the pipeline. The stage block defines the task performed through the Pipeline (e.g. \"Build\", \"Test\" and \"Deploy\" stages) The steps block defines the actions that are to be performed within a particular stage. sh keyword is used to execute shell commands through Jenkins. Lastly, mvn over here stands for maven. Deploying the files to Production VM For deploying our files from the Jenkins VM to production VM, I did the SSH Access configuration. I set up an SSH access configuration for Jenkins to be able to perform operations and copy application files onto the Production VM to allow the Jenkins User to log on to the Production VM without entering for a password again and again. SSH Access Configuration I referred to this document because the way it is explained is easy to understand. Step 1: Create the RSA Key Pair The first step is to create the key pair on the jenkins-infra VM : ssh-keygen -t rsa Step 2: Store the Keys and Passphrase Once I entered the above command, I got a few more questions: Enter file in which to save the key (/home/.ssh/id_rsa): I pressed enter here, saving the file to the mentioned path. Enter passphrase (empty for no passphrase): I pressed enter because if I have given a passphrase, is then having to type it in each time I use the key pair. After this, I got the public key and private key location. Step 3: Copy the Public Key The public key generated above was added to ~/.ssh/authorized_keys on the Production VM. ssh-copy-id jenkins@192.168.1.4 Copying the folder For copying the target folder of Jenkins-Maven Project from Jenkins VM to production VM, it didn't ask for the password this time: scp -r /var/lib/jenkins/workspace/Jenkins-Maven/target production@192.168.1.4:/home/production/target Syntax: scp < source > < destination > In this A is Jenkins VM and B is production VM. To copy a file from B to A while logged into B : scp -r /path/to/file username@A:/path/to/destination To copy a file from B to A while logged into A : scp -r username@B:/path/to/file /path/to/destination","title":"Setting Up Pipeline"},{"location":"setting-up-pipeline/#setting-up-pipeline","text":"","title":"Setting up pipeline"},{"location":"setting-up-pipeline/#objective","text":"This section aims to set up a basic pipeline in Jenkins to perform the task and solve the 4th point of the problem statement under Task 1.","title":"Objective"},{"location":"setting-up-pipeline/#why-pipeline","text":"Jenkins is, fundamentally, an automation engine that supports several automation patterns. Pipeline adds a powerful set of automation tools onto Jenkins, supporting use cases that span from simple continuous integration to comprehensive CD pipelines. By modeling a series of related tasks, Pipeline has many features: Code: Pipelines are implemented in code and typically checked into source control, giving teams the ability to edit, review, and iterate upon their delivery pipeline. Durable: Pipelines can survive both planned and unplanned restarts of the Jenkins master. Pausable: Pipelines can optionally stop and wait for human input or approval before continuing the Pipeline run. Versatile: Pipelines support complex real-world CD requirements, including the ability to fork/join, loop, and perform work in parallel. Extensible: The Pipeline plugin supports custom extensions to its DSL(Domain Specific Language) and multiple options for integration with other plugins.","title":"Why Pipeline?"},{"location":"setting-up-pipeline/#jenkins-pipeline-project","text":"I set up Jenkins as mentioned in the Setup of Jenkins section. For building a pipeline for Maven project I followed these steps and also downloaded Maven in my Jenkins VM for all the repositories related to it are present in the system: Click on the New Item from the main dashboard which leads to a different page. Filled the project name as Jenkins-Maven and choose Maven Project as the project type as it was a Maven based project. Next come's the project configurations page. Here: Under General section: I gave a description of the application being deployed and the purpose of this pipeline. Under the Source Code Management option I checked the Git option and provided the GitHub URL for the project's repository. This option allow's Jenkins to know where to fetch the project from. Under Build Triggers section: I checked the Build whenever a SNAPSHOT dependency is built option to allow automated builds. I clicked on save to save the configurations.","title":"Jenkins pipeline Project"},{"location":"setting-up-pipeline/#jenkinsfile","text":"Jenkinsfile is defined as a utility where the actions that are to be performed on the build can be written in a syntactical format in a file. I followed this official documentation , as it has a simple format with examples. The following are the contents of the Jenkinsfile which executes the pipeline: pipeline { agent any stages { stage ('Compile Stage') { steps { withMaven(maven : 'maven_3_5_0') { sh 'mvn clean compile' } } } stage ('Testing Stage') { steps { withMaven(maven : 'maven_3_5_0') { sh 'mvn test' } } } stage ('Deployment Stage') { steps { withMaven(maven : 'maven_3_5_0') { sh 'mvn deploy' } } } } } The pipeline block constitutes the entire definition of the pipeline. The agent keyword is used to choose the way the Jenkins instance(s) are used to run the pipeline. The any keyword defines that Jenkins should allocate any available agent (an instance of Jenkins/a slave/the master instance) to execute the pipeline. A more thorough explanation can be found here . The stages block houses all the stages that will comprise the various operations to be performed during the execution of the pipeline. The stage block defines the task performed through the Pipeline (e.g. \"Build\", \"Test\" and \"Deploy\" stages) The steps block defines the actions that are to be performed within a particular stage. sh keyword is used to execute shell commands through Jenkins. Lastly, mvn over here stands for maven.","title":"Jenkinsfile"},{"location":"setting-up-pipeline/#deploying-the-files-to-production-vm","text":"For deploying our files from the Jenkins VM to production VM, I did the SSH Access configuration. I set up an SSH access configuration for Jenkins to be able to perform operations and copy application files onto the Production VM to allow the Jenkins User to log on to the Production VM without entering for a password again and again.","title":"Deploying the files to Production VM"},{"location":"setting-up-pipeline/#ssh-access-configuration","text":"I referred to this document because the way it is explained is easy to understand. Step 1: Create the RSA Key Pair The first step is to create the key pair on the jenkins-infra VM : ssh-keygen -t rsa Step 2: Store the Keys and Passphrase Once I entered the above command, I got a few more questions: Enter file in which to save the key (/home/.ssh/id_rsa): I pressed enter here, saving the file to the mentioned path. Enter passphrase (empty for no passphrase): I pressed enter because if I have given a passphrase, is then having to type it in each time I use the key pair. After this, I got the public key and private key location. Step 3: Copy the Public Key The public key generated above was added to ~/.ssh/authorized_keys on the Production VM. ssh-copy-id jenkins@192.168.1.4","title":"SSH Access Configuration"},{"location":"setting-up-pipeline/#copying-the-folder","text":"For copying the target folder of Jenkins-Maven Project from Jenkins VM to production VM, it didn't ask for the password this time: scp -r /var/lib/jenkins/workspace/Jenkins-Maven/target production@192.168.1.4:/home/production/target Syntax: scp < source > < destination > In this A is Jenkins VM and B is production VM. To copy a file from B to A while logged into B : scp -r /path/to/file username@A:/path/to/destination To copy a file from B to A while logged into A : scp -r username@B:/path/to/file /path/to/destination","title":"Copying the folder"},{"location":"setting-up-suitecrm/","text":"Setting up SuiteCRM Objective SuiteCRM should get deployed in a server that is the second VM, to perform the task and solve the 5th point of the problem statement under Task 1. SuiteCRM The application that I chose is SuiteCRM . It is a Customer Relationship Management tool which is the open-source forked version of SugarCRM . SuiteCRM adds a few additional features to its fork and is free to use. I chose the application because it is easy to download and deployed faster and it is also an application that is used in the real-world and is not just a dummy application. I checked out the requirements for installing SuiteCRM and made a workflow on how to carry on further tasks. SuiteCRM is written in PHP and I had to install dependencies on the production VM manually. Dependencies Install PHP(PHP version 5.5.9, or 7.0 and above) Install MySQL Install Apache Web Server Install PHP on Ubuntu 18.04 Ubuntu 18.04 has PHP 7.2 in its repositories. I Installed it by running the commands below in terminal: sudo apt-get -y install wget php php-{pear,cgi,common,curl,mbstring,gd,mysql,gettext,bcmath,imap,json,xml,fpm} Install the required software stack for SuiteCRM. This includes the LAMP stack and some additional PHP modules. sudo apt-get install apache2 apache2-utils libapache2-mod-php php php-common php-curl php-xml php-json php- To confirm that the PHP version is installed. php -v Installing MySQL sudo apt install mysql-server sudo mysql_secure_installation Building a database: create database suitecrm; grant all on suitecrm.* to suitecrm@localhost IDENTIFIED by \"StrongPassword\"; flush privileges; quit Installing Apache Web Server For installing Apache server I followed this documentation . This documentation is written is easy to understand. Step 1 \u2014 Installing Apache sudo apt update sudo apt install apache2 List the ufw application profiles by typing: sudo ufw app list A list of the application profiles: Available applications: Apache Apache Full Apache Secure OpenSSH There are three profiles available for Apache: Apache: This profile opens only port 80 (normal, unencrypted web traffic) Apache Full: This profile opens both port 80 (normal, unencrypted web traffic) and port 443 (TLS/SSL encrypted traffic) Apache Secure: This profile opens only port 443 (TLS/SSL encrypted traffic) Now to check the open ports sudo ufw status Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8080 ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8080 (v6) ALLOW Anywhere (v6) To allow the Apache port. sudo ufw allow 'Apache' Again check the status to see the open ports. sudo ufw status I can see the following ports open now including Apache. Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8080 ALLOW Anywhere Apache ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8080 (v6) ALLOW Anywhere (v6) Apache (v6) ALLOW Anywhere (v6) Check with the systemd init system to make sure the service is running by typing: sudo systemctl status apache2 Once check that the Apache is active after that run on the browser http://IP of production VM . I saw the default Ubuntu 18.04 Apache web page on a web browser which indicates it's working properly. Cloning SuiteCRM To clone SuiteCRM from GitHub firstly I fork the SuiteCRM and after that cloned it to my production system. git clone https://github.com/Priyam5/SuiteCRM.git Installing Composer SuiteCRM packages are not built. This is because I cloned the repository instead of using the zip archive. Hence, I had to install Composer, the package manager for PHP. I followed the official documentation and performed required steps to install Composer globally. After a successful installation, I ran composer install in the project's root directory to build the dependencies for SuiteCRM. php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\" php -r \"if (hash_file('sha384', 'composer-setup.php') === '8a6138e2a05a8c28539c9f0fb361159823655d7ad2deecb371b04a83966c61223adc522b0189079e3e9e277cd72b8897') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHP_EOL;\" php composer-setup.php php -r \"unlink('composer-setup.php');\" To check composer is installed: php composer.phar Errors Resolved I copied the files from SuiteCRM directory to location /var/www/html/suitecrm because to run the application SuiteCRM. When I tried running on a browser the URL, I got this error: Composer autoloader not found. please run \"composer install\" In terminal, I ran the composer install and I got the list of issues: Your requirements could not be resolved to an installable set of packages. Problem 1 - The requested PHP extension ext-gd * is missing from your system. Install or enable PHP's gd extension. Problem 2 - The requested PHP extension ext-zip * is missing from your system. Install or enable PHP's zip extension. Problem 3 - The requested PHP extension ext-imap * is missing from your system. Install or enable PHP's imap extension. Problem 4 - Installation request for jeremykendall/php-domain-parser 4.0.3-alpha -> satisfiable by jeremykendall/php-domain-parser[4.0.3-alpha]. - jeremykendall/php-domain-parser 4.0.3-alpha requires ext-intl * -> the requested PHP extension intl is missing from your system. Problem 5 - Installation request for lcobucci/jwt 3.3.2 -> satisfiable by lcobucci/jwt[3.3.2]. - lcobucci/jwt 3.3.2 requires ext-mbstring * -> the requested PHP extension mbstring is missing from your system. Problem 6 - Installation request for league/uri 4.2.3 -> satisfiable by league/uri[4.2.3]. - league/uri 4.2.3 requires ext-intl * -> the requested PHP extension intl is missing from your system. Problem 7 - Installation request for codeception/codeception 3.1.2 -> satisfiable by codeception/codeception[3.1.2]. - codeception/codeception 3.1.2 requires ext-mbstring * -> the requested PHP extension mbstring is missing from your system. Problem 8 - Installation request for facebook/webdriver 1.7.1 -> satisfiable by facebook/webdriver[1.7.1]. - facebook/webdriver 1.7.1 requires ext-mbstring * -> the requested PHP extension mbstring is missing from your system. Problem 9 - Installation request for phpunit/phpunit 5.7.27 -> satisfiable by phpunit/phpunit[5.7.27]. - phpunit/phpunit 5.7.27 requires ext-mbstring * -> the requested PHP extension mbstring is missing from your system. Problem 10 - lcobucci/jwt 3.3.2 requires ext-mbstring * -> the requested PHP extension mbstring is missing from your system. - league/oauth2-server 5.1.6 requires lcobucci/jwt ^3.1 -> satisfiable by lcobucci/jwt[3.3.2]. - Installation request for league/oauth2-server 5.1.6 -> satisfiable by league/oauth2-server[5.1.6]. In terminal, I ran the following commands to sort out the above issues and install the packages mentioned: sudo apt install php-gd sudo apt install zip php-imap sudo apt install php-zip sudo apt-get install php7.2-mbstring sudo apt-get install php7.2-intl I got the next error when I ran again composer install [RuntimeException] /var/www/html/suitecrm/vendor does not exist and could not be created. Note: I ran the below command and added sudo so the above directory got created. sudo php composer.phar install Access SuiteCRM Web Interface I entered on browser http://IP/suitecrm/install.php for accessing the SuiteCRM Web Interface the screen opens like this: Accept the License and press Enter a new page will open. Again there were two issues to resolve them, I went to the location /etc/php/7.2/apache2/php.ini and entered the command sudo nano /etc/php/7.2/apache2/php.ini Made these changes in the php.ini file: upload_max_filesize = 100M cgi.fix_pathinfo=0 session.save_path = \"var/www/html/suitecrm/\" After this, the System Environment page opened showing, all the system environment parameters. Click next , and then another screen opens, enter the database name, hostname, username, and password. Also, specify the Admin user details on the right side of the screen. I forgot the MySQL password of my database so I ran this below command to reset the password. ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password'; After filling the entries, click next and the SuiteCRM will start installing. As it completes the SuiteCRM login screen will open.","title":"Setting Up SuiteCRM"},{"location":"setting-up-suitecrm/#setting-up-suitecrm","text":"","title":"Setting up SuiteCRM"},{"location":"setting-up-suitecrm/#objective","text":"SuiteCRM should get deployed in a server that is the second VM, to perform the task and solve the 5th point of the problem statement under Task 1.","title":"Objective"},{"location":"setting-up-suitecrm/#suitecrm","text":"The application that I chose is SuiteCRM . It is a Customer Relationship Management tool which is the open-source forked version of SugarCRM . SuiteCRM adds a few additional features to its fork and is free to use. I chose the application because it is easy to download and deployed faster and it is also an application that is used in the real-world and is not just a dummy application. I checked out the requirements for installing SuiteCRM and made a workflow on how to carry on further tasks. SuiteCRM is written in PHP and I had to install dependencies on the production VM manually.","title":"SuiteCRM"},{"location":"setting-up-suitecrm/#dependencies","text":"Install PHP(PHP version 5.5.9, or 7.0 and above) Install MySQL Install Apache Web Server","title":"Dependencies"},{"location":"setting-up-suitecrm/#install-php-on-ubuntu-1804","text":"Ubuntu 18.04 has PHP 7.2 in its repositories. I Installed it by running the commands below in terminal: sudo apt-get -y install wget php php-{pear,cgi,common,curl,mbstring,gd,mysql,gettext,bcmath,imap,json,xml,fpm} Install the required software stack for SuiteCRM. This includes the LAMP stack and some additional PHP modules. sudo apt-get install apache2 apache2-utils libapache2-mod-php php php-common php-curl php-xml php-json php- To confirm that the PHP version is installed. php -v","title":"Install PHP on Ubuntu 18.04"},{"location":"setting-up-suitecrm/#installing-mysql","text":"sudo apt install mysql-server sudo mysql_secure_installation Building a database: create database suitecrm; grant all on suitecrm.* to suitecrm@localhost IDENTIFIED by \"StrongPassword\"; flush privileges; quit","title":"Installing MySQL"},{"location":"setting-up-suitecrm/#installing-apache-web-server","text":"For installing Apache server I followed this documentation . This documentation is written is easy to understand. Step 1 \u2014 Installing Apache sudo apt update sudo apt install apache2 List the ufw application profiles by typing: sudo ufw app list A list of the application profiles: Available applications: Apache Apache Full Apache Secure OpenSSH There are three profiles available for Apache: Apache: This profile opens only port 80 (normal, unencrypted web traffic) Apache Full: This profile opens both port 80 (normal, unencrypted web traffic) and port 443 (TLS/SSL encrypted traffic) Apache Secure: This profile opens only port 443 (TLS/SSL encrypted traffic) Now to check the open ports sudo ufw status Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8080 ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8080 (v6) ALLOW Anywhere (v6) To allow the Apache port. sudo ufw allow 'Apache' Again check the status to see the open ports. sudo ufw status I can see the following ports open now including Apache. Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8080 ALLOW Anywhere Apache ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8080 (v6) ALLOW Anywhere (v6) Apache (v6) ALLOW Anywhere (v6) Check with the systemd init system to make sure the service is running by typing: sudo systemctl status apache2 Once check that the Apache is active after that run on the browser http://IP of production VM . I saw the default Ubuntu 18.04 Apache web page on a web browser which indicates it's working properly.","title":"Installing Apache Web Server"},{"location":"setting-up-suitecrm/#cloning-suitecrm","text":"To clone SuiteCRM from GitHub firstly I fork the SuiteCRM and after that cloned it to my production system. git clone https://github.com/Priyam5/SuiteCRM.git","title":"Cloning  SuiteCRM"},{"location":"setting-up-suitecrm/#installing-composer","text":"SuiteCRM packages are not built. This is because I cloned the repository instead of using the zip archive. Hence, I had to install Composer, the package manager for PHP. I followed the official documentation and performed required steps to install Composer globally. After a successful installation, I ran composer install in the project's root directory to build the dependencies for SuiteCRM. php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\" php -r \"if (hash_file('sha384', 'composer-setup.php') === '8a6138e2a05a8c28539c9f0fb361159823655d7ad2deecb371b04a83966c61223adc522b0189079e3e9e277cd72b8897') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHP_EOL;\" php composer-setup.php php -r \"unlink('composer-setup.php');\" To check composer is installed: php composer.phar","title":"Installing Composer"},{"location":"setting-up-suitecrm/#errors-resolved","text":"I copied the files from SuiteCRM directory to location /var/www/html/suitecrm because to run the application SuiteCRM. When I tried running on a browser the URL, I got this error: Composer autoloader not found. please run \"composer install\" In terminal, I ran the composer install and I got the list of issues: Your requirements could not be resolved to an installable set of packages. Problem 1 - The requested PHP extension ext-gd * is missing from your system. Install or enable PHP's gd extension. Problem 2 - The requested PHP extension ext-zip * is missing from your system. Install or enable PHP's zip extension. Problem 3 - The requested PHP extension ext-imap * is missing from your system. Install or enable PHP's imap extension. Problem 4 - Installation request for jeremykendall/php-domain-parser 4.0.3-alpha -> satisfiable by jeremykendall/php-domain-parser[4.0.3-alpha]. - jeremykendall/php-domain-parser 4.0.3-alpha requires ext-intl * -> the requested PHP extension intl is missing from your system. Problem 5 - Installation request for lcobucci/jwt 3.3.2 -> satisfiable by lcobucci/jwt[3.3.2]. - lcobucci/jwt 3.3.2 requires ext-mbstring * -> the requested PHP extension mbstring is missing from your system. Problem 6 - Installation request for league/uri 4.2.3 -> satisfiable by league/uri[4.2.3]. - league/uri 4.2.3 requires ext-intl * -> the requested PHP extension intl is missing from your system. Problem 7 - Installation request for codeception/codeception 3.1.2 -> satisfiable by codeception/codeception[3.1.2]. - codeception/codeception 3.1.2 requires ext-mbstring * -> the requested PHP extension mbstring is missing from your system. Problem 8 - Installation request for facebook/webdriver 1.7.1 -> satisfiable by facebook/webdriver[1.7.1]. - facebook/webdriver 1.7.1 requires ext-mbstring * -> the requested PHP extension mbstring is missing from your system. Problem 9 - Installation request for phpunit/phpunit 5.7.27 -> satisfiable by phpunit/phpunit[5.7.27]. - phpunit/phpunit 5.7.27 requires ext-mbstring * -> the requested PHP extension mbstring is missing from your system. Problem 10 - lcobucci/jwt 3.3.2 requires ext-mbstring * -> the requested PHP extension mbstring is missing from your system. - league/oauth2-server 5.1.6 requires lcobucci/jwt ^3.1 -> satisfiable by lcobucci/jwt[3.3.2]. - Installation request for league/oauth2-server 5.1.6 -> satisfiable by league/oauth2-server[5.1.6]. In terminal, I ran the following commands to sort out the above issues and install the packages mentioned: sudo apt install php-gd sudo apt install zip php-imap sudo apt install php-zip sudo apt-get install php7.2-mbstring sudo apt-get install php7.2-intl I got the next error when I ran again composer install [RuntimeException] /var/www/html/suitecrm/vendor does not exist and could not be created. Note: I ran the below command and added sudo so the above directory got created. sudo php composer.phar install","title":"Errors Resolved"},{"location":"setting-up-suitecrm/#access-suitecrm-web-interface","text":"I entered on browser http://IP/suitecrm/install.php for accessing the SuiteCRM Web Interface the screen opens like this: Accept the License and press Enter a new page will open. Again there were two issues to resolve them, I went to the location /etc/php/7.2/apache2/php.ini and entered the command sudo nano /etc/php/7.2/apache2/php.ini Made these changes in the php.ini file: upload_max_filesize = 100M cgi.fix_pathinfo=0 session.save_path = \"var/www/html/suitecrm/\" After this, the System Environment page opened showing, all the system environment parameters. Click next , and then another screen opens, enter the database name, hostname, username, and password. Also, specify the Admin user details on the right side of the screen. I forgot the MySQL password of my database so I ran this below command to reset the password. ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password'; After filling the entries, click next and the SuiteCRM will start installing. As it completes the SuiteCRM login screen will open.","title":"Access SuiteCRM Web Interface"}]}