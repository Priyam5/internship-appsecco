{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Project Title: Cloud Native Implementation of DevSecOps Concepts Author: Priyam Singh Mentor: Akash Mahajan , Sunesh Govindaraj , Ayush Priya The report documents the tasks I am working and practicing as a part of my internship at Appsecco on Cloud Native implementation of DevSecOps concepts for an application as well as the issues I am facing while working, and how I resolved them.","title":"Introduction"},{"location":"#introduction","text":"Project Title: Cloud Native Implementation of DevSecOps Concepts Author: Priyam Singh Mentor: Akash Mahajan , Sunesh Govindaraj , Ayush Priya The report documents the tasks I am working and practicing as a part of my internship at Appsecco on Cloud Native implementation of DevSecOps concepts for an application as well as the issues I am facing while working, and how I resolved them.","title":"Introduction"},{"location":"code-quality-analysis/","text":"Code Quality Analysis Objective This section aims to perform a linting check on the source code of angular-realworld-example-app and generate a report to provide a solution to the 2nd point of the problem statement under Task 1. Code Linting Linting is the automated checking of source code for programmatic and stylistic errors. This is done by using a linting tool. A lint tool is a basic static code analyzer. Linting is important to reduce errors and improve the overall quality of code. Using lint tools can help accelerate development and reduce costs by finding errors earlier. Linting tools are language-specific and thus, the tool that can be used depends on the application being tested. Nowadays, we have different linters, which provide many types of checks like syntax errors, code standards adherence, potential problems, security checks. Linting tools for angular-realworld-example-app Angular-realworld-example-app is a JavaScript application and hence, I used jshint as the linter. I primarily chose jshint as it is available as a command-line utility and hence, I used this documentation for using jshint. Writing YAML file in GitHub Action I created a new file linting-tool.yml in the .github/workflows The YAML file is shown below: name: \"linting-tool-scan\" on: push: branches: [master] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: install dependencies run: | sudo apt install npm sudo npm install --package-lock npm audit fix - name: Installing JSHint run: | sudo npm install -g jshint - name: Run scan with JSHint run: script/jshint-script.sh - name: Archive production artifacts uses: actions/upload-artifact@v2 with: name: linting tool report path: | ./JSHint-report node_modules It excludes the node_modules/ directory and also exclude any files which do not have a .js or .ejs extension --reporter By using this option, I can change the output format. I selected unix , as it will become easier to count the rows and words. There are other options like checkstyle , the output will be in an xml format I was getting an error a non-zero status code, when it found issues. So, I made a directory and stored bash script to run the scan in a sub-shell and prevent the build from failing and made it executable with chmod +x . The contents of the script, jshint-script.sh , are below: #!/bin/bash jshint --exclude=\"node_modules/\" --reporter=unix . > JSHint-report echo $? > /dev/null Lastly, I stored the report as a artifact.","title":"Code Quality Analysis"},{"location":"code-quality-analysis/#code-quality-analysis","text":"","title":"Code Quality Analysis"},{"location":"code-quality-analysis/#objective","text":"This section aims to perform a linting check on the source code of angular-realworld-example-app and generate a report to provide a solution to the 2nd point of the problem statement under Task 1.","title":"Objective"},{"location":"code-quality-analysis/#code-linting","text":"Linting is the automated checking of source code for programmatic and stylistic errors. This is done by using a linting tool. A lint tool is a basic static code analyzer. Linting is important to reduce errors and improve the overall quality of code. Using lint tools can help accelerate development and reduce costs by finding errors earlier. Linting tools are language-specific and thus, the tool that can be used depends on the application being tested. Nowadays, we have different linters, which provide many types of checks like syntax errors, code standards adherence, potential problems, security checks.","title":"Code Linting"},{"location":"code-quality-analysis/#linting-tools-for-angular-realworld-example-app","text":"Angular-realworld-example-app is a JavaScript application and hence, I used jshint as the linter. I primarily chose jshint as it is available as a command-line utility and hence, I used this documentation for using jshint.","title":"Linting tools for angular-realworld-example-app"},{"location":"code-quality-analysis/#writing-yaml-file-in-github-action","text":"I created a new file linting-tool.yml in the .github/workflows The YAML file is shown below: name: \"linting-tool-scan\" on: push: branches: [master] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: install dependencies run: | sudo apt install npm sudo npm install --package-lock npm audit fix - name: Installing JSHint run: | sudo npm install -g jshint - name: Run scan with JSHint run: script/jshint-script.sh - name: Archive production artifacts uses: actions/upload-artifact@v2 with: name: linting tool report path: | ./JSHint-report node_modules It excludes the node_modules/ directory and also exclude any files which do not have a .js or .ejs extension --reporter By using this option, I can change the output format. I selected unix , as it will become easier to count the rows and words. There are other options like checkstyle , the output will be in an xml format I was getting an error a non-zero status code, when it found issues. So, I made a directory and stored bash script to run the scan in a sub-shell and prevent the build from failing and made it executable with chmod +x . The contents of the script, jshint-script.sh , are below: #!/bin/bash jshint --exclude=\"node_modules/\" --reporter=unix . > JSHint-report echo $? > /dev/null Lastly, I stored the report as a artifact.","title":"Writing YAML file in GitHub Action"},{"location":"contents/","text":"Table of contents The following is the report/documentation for the Problem Statement stated in next section. The contents of the report are: Introduction Contents Problem Statement SAST through GitHub Action Code Quality Analysis Software Bill of Materials Set up GitHub Actions Workflow for DAST Set up GitHub Actions Workflow for Deployment","title":"Contents"},{"location":"contents/#table-of-contents","text":"The following is the report/documentation for the Problem Statement stated in next section. The contents of the report are: Introduction Contents Problem Statement SAST through GitHub Action Code Quality Analysis Software Bill of Materials Set up GitHub Actions Workflow for DAST Set up GitHub Actions Workflow for Deployment","title":"Table of contents"},{"location":"dast/","text":"Set up GitHub Actions Workflow for DAST Objective This section aims to perform a DAST scan on angular-realworld-example-app and generate a report to provide a solution to the 4th point of the problem statement under Task 1. Setting Up the application manually Firstly, I installed the application manually and ran it on my browser to know how it works. So I cloned the application in my terminal git clone https://github.com/gothinkster/angular-realworld-example-app.git Install npm sudo apt update sudo apt install nodejs sudo apt install npm nodejs -v Install Yarn (https://classic.yarnpkg.com/en/docs/install/#debian-stable) curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list sudo apt update && sudo apt install yarn export PATH=\"$PATH:`yarn global bin`\" yarn install yarn -version Install Angular CLI(https://angular.io/cli) npm install -g @angular/cli Got an error as on running ng serve opens editor instead of loading local URL. This is the terminal editor on the 'ng' alias. I uninstalled it with: sudo apt purge ng-common ng-latin Now again I ran ng serve and in the browser I typed localhost:4200 (4200 is the default port). The application was successfully installed and window that opened is shown below: Setting Up the application through Docker I firstly cloned the application and in the cloned folder made a file Dockerfile . In this, I used a node image nano Dockerfile I wrote this code in Dockerfile #getting base image FROM node MAINTAINER Priyam Singh <2020priyamsingh@gmail.com> RUN apt-get update COPY . /src WORKDIR /src #Installing Angular CLI RUN npm install RUN npm install -y -g @angular-devkit/build-angular RUN npm install -y -g @angular/cli EXPOSE 4200 CMD [\"ng\", \"serve\", \"--host\", \"0.0.0.0\"] My application was not running on browser but it was getting compiled because I made a mistake that I was not writing \"--host\", \"0.0.0.0\" (--host 0.0.0.0 to listen to all the interfaces from the container). I was facing many errors such as packages getting failed so I removed my code of Yarn and only installed with Angular CLI After this, I build the image docker build -t angular5:latest . Then ran the container docker run --rm --name docker5 -p 1234:4200 angular5:latest On the browser I opened localhost:1234 it worked and the below window got opened. Setting Up application through AWS Installing AWS CLI in terminal I followed this official link for the installation of AWS CLI and ran the below commands: curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install aws --version I got the version output as shown below. It means AWS CLI is successfully installed. aws-cli/2.0.56 Python/3.7.3 Linux/5.3.0-64-generic exe/x86_64.ubuntu.19 Setting up AWS profile For setting up AWS profile I followed this official documentation . I ran the command aws configure to set up AWS CLI installation. It will ask for some information which we have to enter: AWS Access Key ID [****************4529]: <Enter the ID> AWS Secret Access Key [None]: <Enter the Access Key> Default region name [None]: us-east-2 Default output format [None]: json Then run the below command: aws sts get-caller-identity We will get the below output and our profile has been successfully configured: \"UserId\": <\"AWS Access Key ID \">, \"Account\": <\"ACCOUNT NO.\">, \"Arn\": \"******\" ECR Amazon Elastic Container Registry (ECR) is a fully-managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images. Amazon ECR eliminates the need to operate our container repositories or worry about scaling the underlying infrastructure. Amazon ECR hosts our images in a highly available and scalable architecture, allowing us to reliably deploy containers for our applications. Creating an ECR Repository To Create the ECR Repository I followed the below steps: I opened the Amazon ECR console In the navigation pane, choose Repositories On the Repositories page, choose Create repository In Repository name , enter a unique name for repository For Tag immutability , I choose the tag mutability setting for the repository. Repositories configured with immutable tags will prevent image tags from being overwritten For Scan on push , I choose the image scanning setting for the repository. Repositories configured to scan on push will start an image scan whenever an image is pushed, otherwise, image scans need to be started manually For KMS encryption , I choose to enable encryption of the images in the repository using AWS Key Management Service Deleting an ECR repository To delete an ECR repository I followed the below steps: I opened the Amazon ECR console In the navigation pane, I choose Repositories On the Repositories page, I selected the repository to delete and choose Delete In the Delete repository_name window, I verified that the selected repositories to be deleted and choose Delete option. Pushing an ECR Repository When we create a repository it shows commands for pushing. So we have to follow these commands and we can easily push the image to our ECR Repository. aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com docker tag angular5:latest ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest docker push ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest Adding an image to ECR Repository through GitHub Actions I created a new file image.yml in the .github/workflows . I stored my credentials in the secrets section of my application repository. I used this plugin \"Configure AWS Credentials\" Action For GitHub Actions for AWS configuration. Below is the YML file: name: \"build image from Dockerfile\" on: push: branches: [master] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Install docker run: | sudo apt update sudo apt install apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\" && sudo apt update apt-cache policy docker-ce sudo apt install docker-ce - name: Build Docker image run: | docker build -t angular5 . - name: Installing AWS CLI run: | curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v1 with: aws-access-key-id: ${{ secrets.DEMO_ID }} aws-secret-access-key: ${{ secrets.DEMO_K }} aws-region: us-east-2 - name: Pushing image to AWS run: | aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com docker tag angular5:latest ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest docker push ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest After this, the image got successfully pushed to ECR. ECS Amazon Elastic Container Service (ECS) is a highly scalable, high performance container management service that supports Docker containers and allows to easily run applications on a managed cluster of Amazon EC2 instances. It eliminates the need for us to install, operate, and scale cluster management infrastructure. Setting Up ECS cluster To create cluster I followed the steps given below and also followed the official link . For creating a cluster: I clicked on services in the left upper corner and searched for ECS under All services and clicked Elastic Container Service . I selected Clusters option and then Create Clusters For Select cluster template , I selected Networking only because I wanted to make it by Fargate as Fargate is a technology that can be used with Amazon ECS to run containers without having to manage servers or clusters of Amazon EC2 instances. With AWS Fargate, no longer have to provision, configure, or scale clusters of virtual machines to run containers., then I selected Next Step . The next page opened, here I have to fill the cluster name and click create . The Launch status page opened showing it is successfully created. Setting Up Task Definitions From the side bar select Create new Task Definition and the page opens to select FARGATE and click Next step Over here give the Task Definition Name and Task Role select ecsTaskExecutionRole Task memory (GB) select 0.5GB and in Task CPU (vCPU) select 0.25 vCPU and finally select Create option. Setting Up Service An Amazon ECS service enables us to run and maintain a specified number of instances of a task definition simultaneously in an Amazon ECS cluster. If any of our tasks fail or stop for any reason, the Amazon ECS service scheduler launches another instance of our task definition to replace it in order to maintain the desired number of tasks in the service. After creating the ECS cluster, now I can create Services for the cluster. I followed this official documentation . I firstly clicked on the cluster which I made and selected the Service option then clicked on Create . The next page Configure service opens (a). In the Launch Type I selected FARGATE then filled the Service name and in Number of tasks I typed 1. Other options I kept as default and then selected Next step . The next pages opened Configure network in this I selected the Cluster VPC and Subnets and in Configure security groups I created a new security group. (a). I selected Create new security group (b). Entered security group name Security group name (c). Define Inbound rules for security group , it can be changed later if required Set Auto Scaling that too I kept default and selected the Next step Then Review page opens in which we can review the changes and finally create the service Once the service is successfully created I accessed the public IP of the task running and in the browser entered Public IP:4200 . The application is running as shown below: Setting Up YAML file for ZAP scan ZAP scan: Zed Attack Proxy is an open-source tool used to perform dynamic application security testing designed specifically for web applications. ZAP has a desktop interface, APIs for it to be used in an automated fashion, and also a CLI. I added these steps in YML file for ZAP scan: - name: ZAP scan run: script/zap-script.sh - name: Archive production artifacts uses: actions/upload-artifact@v2 with: name: zap report path: | ./zap_baseline_report.html The ZAP scan was getting failed so made a dedicated service as earlier for the zap scan and in the Security Group I selected the protocol type as Custom TCP and port range 4200 and in Source I selected Custom and selected 0.0.0.0/0 which allowed all the traffic. As over here also I was getting an error a non-zero status code, when it found issues after ZAP scan. So, I made a directory and stored bash script to run the scan in a sub-shell and prevent the build from failing and made it executable with chmod +x. The contents of the script, zap-script.sh , are below: #!/bin/bash docker pull owasp/zap2docker-stable docker run -i owasp/zap2docker-stable zap-baseline.py -t \"http://3.135.209.44:4200/\" -l PASS > zap_baseline_report.html echo $? > /dev/null I stored the reports in the artifacts.","title":"Set up GitHub Actions Workflow for DAST"},{"location":"dast/#set-up-github-actions-workflow-for-dast","text":"","title":"Set up GitHub Actions Workflow for DAST"},{"location":"dast/#objective","text":"This section aims to perform a DAST scan on angular-realworld-example-app and generate a report to provide a solution to the 4th point of the problem statement under Task 1.","title":"Objective"},{"location":"dast/#setting-up-the-application-manually","text":"Firstly, I installed the application manually and ran it on my browser to know how it works. So I cloned the application in my terminal git clone https://github.com/gothinkster/angular-realworld-example-app.git Install npm sudo apt update sudo apt install nodejs sudo apt install npm nodejs -v Install Yarn (https://classic.yarnpkg.com/en/docs/install/#debian-stable) curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list sudo apt update && sudo apt install yarn export PATH=\"$PATH:`yarn global bin`\" yarn install yarn -version Install Angular CLI(https://angular.io/cli) npm install -g @angular/cli Got an error as on running ng serve opens editor instead of loading local URL. This is the terminal editor on the 'ng' alias. I uninstalled it with: sudo apt purge ng-common ng-latin Now again I ran ng serve and in the browser I typed localhost:4200 (4200 is the default port). The application was successfully installed and window that opened is shown below:","title":"Setting Up the application manually"},{"location":"dast/#setting-up-the-application-through-docker","text":"I firstly cloned the application and in the cloned folder made a file Dockerfile . In this, I used a node image nano Dockerfile I wrote this code in Dockerfile #getting base image FROM node MAINTAINER Priyam Singh <2020priyamsingh@gmail.com> RUN apt-get update COPY . /src WORKDIR /src #Installing Angular CLI RUN npm install RUN npm install -y -g @angular-devkit/build-angular RUN npm install -y -g @angular/cli EXPOSE 4200 CMD [\"ng\", \"serve\", \"--host\", \"0.0.0.0\"] My application was not running on browser but it was getting compiled because I made a mistake that I was not writing \"--host\", \"0.0.0.0\" (--host 0.0.0.0 to listen to all the interfaces from the container). I was facing many errors such as packages getting failed so I removed my code of Yarn and only installed with Angular CLI After this, I build the image docker build -t angular5:latest . Then ran the container docker run --rm --name docker5 -p 1234:4200 angular5:latest On the browser I opened localhost:1234 it worked and the below window got opened.","title":"Setting Up the application through Docker"},{"location":"dast/#setting-up-application-through-aws","text":"","title":"Setting Up application through AWS"},{"location":"dast/#installing-aws-cli-in-terminal","text":"I followed this official link for the installation of AWS CLI and ran the below commands: curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install aws --version I got the version output as shown below. It means AWS CLI is successfully installed. aws-cli/2.0.56 Python/3.7.3 Linux/5.3.0-64-generic exe/x86_64.ubuntu.19","title":"Installing AWS CLI in terminal"},{"location":"dast/#setting-up-aws-profile","text":"For setting up AWS profile I followed this official documentation . I ran the command aws configure to set up AWS CLI installation. It will ask for some information which we have to enter: AWS Access Key ID [****************4529]: <Enter the ID> AWS Secret Access Key [None]: <Enter the Access Key> Default region name [None]: us-east-2 Default output format [None]: json Then run the below command: aws sts get-caller-identity We will get the below output and our profile has been successfully configured: \"UserId\": <\"AWS Access Key ID \">, \"Account\": <\"ACCOUNT NO.\">, \"Arn\": \"******\"","title":"Setting up AWS profile"},{"location":"dast/#ecr","text":"Amazon Elastic Container Registry (ECR) is a fully-managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images. Amazon ECR eliminates the need to operate our container repositories or worry about scaling the underlying infrastructure. Amazon ECR hosts our images in a highly available and scalable architecture, allowing us to reliably deploy containers for our applications.","title":"ECR"},{"location":"dast/#creating-an-ecr-repository","text":"To Create the ECR Repository I followed the below steps: I opened the Amazon ECR console In the navigation pane, choose Repositories On the Repositories page, choose Create repository In Repository name , enter a unique name for repository For Tag immutability , I choose the tag mutability setting for the repository. Repositories configured with immutable tags will prevent image tags from being overwritten For Scan on push , I choose the image scanning setting for the repository. Repositories configured to scan on push will start an image scan whenever an image is pushed, otherwise, image scans need to be started manually For KMS encryption , I choose to enable encryption of the images in the repository using AWS Key Management Service","title":"Creating an ECR Repository"},{"location":"dast/#deleting-an-ecr-repository","text":"To delete an ECR repository I followed the below steps: I opened the Amazon ECR console In the navigation pane, I choose Repositories On the Repositories page, I selected the repository to delete and choose Delete In the Delete repository_name window, I verified that the selected repositories to be deleted and choose Delete option.","title":"Deleting an ECR repository"},{"location":"dast/#pushing-an-ecr-repository","text":"When we create a repository it shows commands for pushing. So we have to follow these commands and we can easily push the image to our ECR Repository. aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com docker tag angular5:latest ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest docker push ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest","title":"Pushing an ECR Repository"},{"location":"dast/#adding-an-image-to-ecr-repository-through-github-actions","text":"I created a new file image.yml in the .github/workflows . I stored my credentials in the secrets section of my application repository. I used this plugin \"Configure AWS Credentials\" Action For GitHub Actions for AWS configuration. Below is the YML file: name: \"build image from Dockerfile\" on: push: branches: [master] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Install docker run: | sudo apt update sudo apt install apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\" && sudo apt update apt-cache policy docker-ce sudo apt install docker-ce - name: Build Docker image run: | docker build -t angular5 . - name: Installing AWS CLI run: | curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v1 with: aws-access-key-id: ${{ secrets.DEMO_ID }} aws-secret-access-key: ${{ secrets.DEMO_K }} aws-region: us-east-2 - name: Pushing image to AWS run: | aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com docker tag angular5:latest ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest docker push ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest After this, the image got successfully pushed to ECR.","title":"Adding an image to ECR Repository through GitHub Actions"},{"location":"dast/#ecs","text":"Amazon Elastic Container Service (ECS) is a highly scalable, high performance container management service that supports Docker containers and allows to easily run applications on a managed cluster of Amazon EC2 instances. It eliminates the need for us to install, operate, and scale cluster management infrastructure.","title":"ECS"},{"location":"dast/#setting-up-ecs-cluster","text":"To create cluster I followed the steps given below and also followed the official link . For creating a cluster: I clicked on services in the left upper corner and searched for ECS under All services and clicked Elastic Container Service . I selected Clusters option and then Create Clusters For Select cluster template , I selected Networking only because I wanted to make it by Fargate as Fargate is a technology that can be used with Amazon ECS to run containers without having to manage servers or clusters of Amazon EC2 instances. With AWS Fargate, no longer have to provision, configure, or scale clusters of virtual machines to run containers., then I selected Next Step . The next page opened, here I have to fill the cluster name and click create . The Launch status page opened showing it is successfully created.","title":"Setting Up ECS cluster"},{"location":"dast/#setting-up-task-definitions","text":"From the side bar select Create new Task Definition and the page opens to select FARGATE and click Next step Over here give the Task Definition Name and Task Role select ecsTaskExecutionRole Task memory (GB) select 0.5GB and in Task CPU (vCPU) select 0.25 vCPU and finally select Create option.","title":"Setting Up Task Definitions"},{"location":"dast/#setting-up-service","text":"An Amazon ECS service enables us to run and maintain a specified number of instances of a task definition simultaneously in an Amazon ECS cluster. If any of our tasks fail or stop for any reason, the Amazon ECS service scheduler launches another instance of our task definition to replace it in order to maintain the desired number of tasks in the service. After creating the ECS cluster, now I can create Services for the cluster. I followed this official documentation . I firstly clicked on the cluster which I made and selected the Service option then clicked on Create . The next page Configure service opens (a). In the Launch Type I selected FARGATE then filled the Service name and in Number of tasks I typed 1. Other options I kept as default and then selected Next step . The next pages opened Configure network in this I selected the Cluster VPC and Subnets and in Configure security groups I created a new security group. (a). I selected Create new security group (b). Entered security group name Security group name (c). Define Inbound rules for security group , it can be changed later if required Set Auto Scaling that too I kept default and selected the Next step Then Review page opens in which we can review the changes and finally create the service Once the service is successfully created I accessed the public IP of the task running and in the browser entered Public IP:4200 . The application is running as shown below:","title":"Setting Up Service"},{"location":"dast/#setting-up-yaml-file-for-zap-scan","text":"ZAP scan: Zed Attack Proxy is an open-source tool used to perform dynamic application security testing designed specifically for web applications. ZAP has a desktop interface, APIs for it to be used in an automated fashion, and also a CLI. I added these steps in YML file for ZAP scan: - name: ZAP scan run: script/zap-script.sh - name: Archive production artifacts uses: actions/upload-artifact@v2 with: name: zap report path: | ./zap_baseline_report.html The ZAP scan was getting failed so made a dedicated service as earlier for the zap scan and in the Security Group I selected the protocol type as Custom TCP and port range 4200 and in Source I selected Custom and selected 0.0.0.0/0 which allowed all the traffic. As over here also I was getting an error a non-zero status code, when it found issues after ZAP scan. So, I made a directory and stored bash script to run the scan in a sub-shell and prevent the build from failing and made it executable with chmod +x. The contents of the script, zap-script.sh , are below: #!/bin/bash docker pull owasp/zap2docker-stable docker run -i owasp/zap2docker-stable zap-baseline.py -t \"http://3.135.209.44:4200/\" -l PASS > zap_baseline_report.html echo $? > /dev/null I stored the reports in the artifacts.","title":"Setting Up YAML file for ZAP scan"},{"location":"deployment/","text":"Set up GitHub Actions Workflow for Deployment Objective This section aims to generate a Software Bill of Materials for angular-realworld-example-app and generate a report to provide a solution to the 5rd point of the problem statement under Task 1. Running GitHub Actions Sequentially I set up the sequential workflows by using a repository_dispatch action in the following four steps and followed the documentation(https://stevenmortimer.com/running-github-actions-sequentially/) : Step1: Creating a Personal Access Token (PAT) I followed the GitHub\u2019s instructions here for creating PAT and in Select scopes I checked repo as the repository is a private repository and if it is a public repo public_repo option is checked. Step 2 - Adding the PAT as an actions secret in the repository In the second step I added the token to secrets and named it as REPO_TRIGGER_PAT . Step 3 - Adding the repository_dispatch event to Workflow 1 that is workflow I made for ZAP scan Workflow 1 is the workflow, and the jobs contained within it, is the one which I want to exacute first. Workflow 2 is the workflow I want to execute after WOrkflow 1 . Given below is the last step of my Workflow 1 : - name: Trigger next workflow if: success() uses: peter-evans/repository-dispatch@v1 with: token: ${{ secrets.REPO_TRIGGER_PAT }} repository: ${{ github.repository }} event-type: trigger-deployment-workflow client-payload: '{\"ref\": \"${{ github.ref }}\", \"sha\": \"${{ github.sha }}\"}' In this if: success() means only if all the prior steps in the Workflow 1 are successful, then only run the steps that triggers Workflow 2 . client-payload: '{\"ref\": \"${{ github.ref }}\", \"sha\": \"${{ github.sha }}\"}' The above command is used to pass the data from Workflow 1 to Workflow 2 . It tells Workflow2 the branch and commit hash to checkout and use so that Workflows 1 and Workflow 2 are using the same exact code. Step 4 - Adding the repository_dispatch event as trigger in Workflow 2 YAML Firstly, in Workflow 2 I added event name as the types of repository dispatch that should trigger Workflow 2 . This name matches exactly as the one specified in the event-type and in the types also same name is used. name: \"deployment workflow\" on: repository_dispatch: types: [trigger-deployment-workflow] I used the client payload data from the event to checkout the same code. I modified the checkout step, the first step in job. steps: - uses: actions/checkout@v2 with: ref: ${{ github.event.client_payload.sha }} After this I add all other steps in Workflow 2 for deployment of application. YAML file for deployment The YAML file for deployment of application is similar to the one I used for Adding an image to ECR Repository through GitHub Actions . In this I have also used the step of redeploying the application. The YAML file is as follows: name: \"deployment workflow\" on: repository_dispatch: types: [trigger-deployment-workflow] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: ref: ${{ github.event.client_payload.sha }} - name: Install docker run: | sudo apt update sudo apt install apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\" && sudo apt update apt-cache policy docker-ce sudo apt install docker-ce - name: Build Docker image run: | docker build -t angular5 . - name: Installing AWS CLI run: | curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v1 with: aws-access-key-id: ${{ secrets.DEMO_ID }} aws-secret-access-key: ${{ secrets.DEMO_K }} aws-region: us-east-2 - name: Pushing image to AWS run: | aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com docker tag angular5:latest ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest docker push ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest - name: redeploy the latest image run: | aws ecs update-service --cluster angular-app --service angular-service --force-new-deployment","title":"Set up GitHub Actions Workflow for Deployment"},{"location":"deployment/#set-up-github-actions-workflow-for-deployment","text":"","title":"Set up GitHub Actions Workflow for Deployment"},{"location":"deployment/#objective","text":"This section aims to generate a Software Bill of Materials for angular-realworld-example-app and generate a report to provide a solution to the 5rd point of the problem statement under Task 1.","title":"Objective"},{"location":"deployment/#running-github-actions-sequentially","text":"I set up the sequential workflows by using a repository_dispatch action in the following four steps and followed the documentation(https://stevenmortimer.com/running-github-actions-sequentially/) : Step1: Creating a Personal Access Token (PAT) I followed the GitHub\u2019s instructions here for creating PAT and in Select scopes I checked repo as the repository is a private repository and if it is a public repo public_repo option is checked. Step 2 - Adding the PAT as an actions secret in the repository In the second step I added the token to secrets and named it as REPO_TRIGGER_PAT . Step 3 - Adding the repository_dispatch event to Workflow 1 that is workflow I made for ZAP scan Workflow 1 is the workflow, and the jobs contained within it, is the one which I want to exacute first. Workflow 2 is the workflow I want to execute after WOrkflow 1 . Given below is the last step of my Workflow 1 : - name: Trigger next workflow if: success() uses: peter-evans/repository-dispatch@v1 with: token: ${{ secrets.REPO_TRIGGER_PAT }} repository: ${{ github.repository }} event-type: trigger-deployment-workflow client-payload: '{\"ref\": \"${{ github.ref }}\", \"sha\": \"${{ github.sha }}\"}' In this if: success() means only if all the prior steps in the Workflow 1 are successful, then only run the steps that triggers Workflow 2 . client-payload: '{\"ref\": \"${{ github.ref }}\", \"sha\": \"${{ github.sha }}\"}' The above command is used to pass the data from Workflow 1 to Workflow 2 . It tells Workflow2 the branch and commit hash to checkout and use so that Workflows 1 and Workflow 2 are using the same exact code. Step 4 - Adding the repository_dispatch event as trigger in Workflow 2 YAML Firstly, in Workflow 2 I added event name as the types of repository dispatch that should trigger Workflow 2 . This name matches exactly as the one specified in the event-type and in the types also same name is used. name: \"deployment workflow\" on: repository_dispatch: types: [trigger-deployment-workflow] I used the client payload data from the event to checkout the same code. I modified the checkout step, the first step in job. steps: - uses: actions/checkout@v2 with: ref: ${{ github.event.client_payload.sha }} After this I add all other steps in Workflow 2 for deployment of application.","title":"Running GitHub Actions Sequentially"},{"location":"deployment/#yaml-file-for-deployment","text":"The YAML file for deployment of application is similar to the one I used for Adding an image to ECR Repository through GitHub Actions . In this I have also used the step of redeploying the application. The YAML file is as follows: name: \"deployment workflow\" on: repository_dispatch: types: [trigger-deployment-workflow] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: ref: ${{ github.event.client_payload.sha }} - name: Install docker run: | sudo apt update sudo apt install apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\" && sudo apt update apt-cache policy docker-ce sudo apt install docker-ce - name: Build Docker image run: | docker build -t angular5 . - name: Installing AWS CLI run: | curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v1 with: aws-access-key-id: ${{ secrets.DEMO_ID }} aws-secret-access-key: ${{ secrets.DEMO_K }} aws-region: us-east-2 - name: Pushing image to AWS run: | aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com docker tag angular5:latest ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest docker push ${{ secrets.AWS_LOG }}.dkr.ecr.us-east-2.amazonaws.com/angular-app-repo:latest - name: redeploy the latest image run: | aws ecs update-service --cluster angular-app --service angular-service --force-new-deployment","title":"YAML file for deployment"},{"location":"github-action/","text":"SAST through Github Action Objective This section aims to perform SAST for angular-realworld-example-app and generate a report to provide a solution to the 1st point of the problem statement under Task 1. SAST Static analysis or Static application security testing (SAST), is a testing methodology that analyzes source code to find security vulnerabilities that make organization\u2019s applications susceptible to attack. SAST scans an application before the code is compiled. It\u2019s also known as white box testing. SAST takes place very early in the software development life cycle (SDLC) as it does not require a working application and can take place without code being executed. It helps in identifying vulnerabilities in the initial stages of development and quickly resolve issues without breaking builds or passing on vulnerabilities to the final release of the application. Github Action GitHub Actions make it easy to automate all software workflows. Github Actions let us build, test, and deploy our code right from GitHub. We can also assign code reviews, manage branches, and triage issues the way we want with actions. GitHub Actions are designed to help in building robust and dynamic automation's. Whether we want to build a container, deploy a web service, or automate welcoming a new user to our open-source project \u2014 there\u2019s an automated action for that. Creating Workflow I followed this official link for creating the first workflow . On GitHub, I forked angular-realworld-example-app and I created a new file in the .github/workflows I wrote the YAML contents into the sast-scan.yml file. For knowing the syntax of Github action I followed this official link I also stored the report as sast report in artifacts from where it can be downloaded The YAML file for SAST scan is as follows: name: \"sast-scan\" on: push: branches: [master] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: install dependencies run: | sudo apt install npm sudo npm install --package-lock npm audit fix first - name: OWASP Dependency Check run: | wget https://github.com/jeremylong/DependencyCheck/releases/download/v6.0.2/dependency-check-6.0.2-release.zip unzip dependency-check-6.0.2-release.zip - name: Run scan with ODC run: | dependency-check/bin/dependency-check.sh --project \"angular-realworld-example-app\" --scan . - name: Archive production artifacts uses: actions/upload-artifact@v2 with: name: sast report path: | ./dependency-check-6.0.2-release.zip To run workflow, I scrolled to the bottom of the page and select Commit directly to the main branch. Then, to create a pull request, click Propose new file . Committing the workflow file in repository triggers the push event and runs workflow. The report that got generated is here Viewing workflow results On GitHub, I navigated to the main page of the repository. Under repository name, click Actions . In the left sidebar, select the workflow to see under All Workflows section. From the list of workflow runs, I selected the name sast-scan of the run to see. In the left sidebar, I selected test and I can also check the sast-scan.yml by selecting Workflow file . Expand the test to view the results and each step expanded further to see the logs.","title":"SAST Github Action"},{"location":"github-action/#sast-through-github-action","text":"","title":"SAST through Github Action"},{"location":"github-action/#objective","text":"This section aims to perform SAST for angular-realworld-example-app and generate a report to provide a solution to the 1st point of the problem statement under Task 1.","title":"Objective"},{"location":"github-action/#sast","text":"Static analysis or Static application security testing (SAST), is a testing methodology that analyzes source code to find security vulnerabilities that make organization\u2019s applications susceptible to attack. SAST scans an application before the code is compiled. It\u2019s also known as white box testing. SAST takes place very early in the software development life cycle (SDLC) as it does not require a working application and can take place without code being executed. It helps in identifying vulnerabilities in the initial stages of development and quickly resolve issues without breaking builds or passing on vulnerabilities to the final release of the application.","title":"SAST"},{"location":"github-action/#github-action","text":"GitHub Actions make it easy to automate all software workflows. Github Actions let us build, test, and deploy our code right from GitHub. We can also assign code reviews, manage branches, and triage issues the way we want with actions. GitHub Actions are designed to help in building robust and dynamic automation's. Whether we want to build a container, deploy a web service, or automate welcoming a new user to our open-source project \u2014 there\u2019s an automated action for that.","title":"Github Action"},{"location":"github-action/#creating-workflow","text":"I followed this official link for creating the first workflow . On GitHub, I forked angular-realworld-example-app and I created a new file in the .github/workflows I wrote the YAML contents into the sast-scan.yml file. For knowing the syntax of Github action I followed this official link I also stored the report as sast report in artifacts from where it can be downloaded The YAML file for SAST scan is as follows: name: \"sast-scan\" on: push: branches: [master] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: install dependencies run: | sudo apt install npm sudo npm install --package-lock npm audit fix first - name: OWASP Dependency Check run: | wget https://github.com/jeremylong/DependencyCheck/releases/download/v6.0.2/dependency-check-6.0.2-release.zip unzip dependency-check-6.0.2-release.zip - name: Run scan with ODC run: | dependency-check/bin/dependency-check.sh --project \"angular-realworld-example-app\" --scan . - name: Archive production artifacts uses: actions/upload-artifact@v2 with: name: sast report path: | ./dependency-check-6.0.2-release.zip To run workflow, I scrolled to the bottom of the page and select Commit directly to the main branch. Then, to create a pull request, click Propose new file . Committing the workflow file in repository triggers the push event and runs workflow. The report that got generated is here","title":"Creating Workflow"},{"location":"github-action/#viewing-workflow-results","text":"On GitHub, I navigated to the main page of the repository. Under repository name, click Actions . In the left sidebar, select the workflow to see under All Workflows section. From the list of workflow runs, I selected the name sast-scan of the run to see. In the left sidebar, I selected test and I can also check the sast-scan.yml by selecting Workflow file . Expand the test to view the results and each step expanded further to see the logs.","title":"Viewing workflow results"},{"location":"problem-statement/","text":"Problem Statement Task 1 Performing SAST on the application through GitHub Actions and generate the report. Performing source Code Quality Analysis for linting errors to improve code quality and generate quality report. Generating Software Bill of Materials of application for all dependencies. Setting up GitHub Actions Workflow for DAST. Setting up GitHub Actions Workflow for the Deployment of Application.","title":"Problem Statement"},{"location":"problem-statement/#problem-statement","text":"","title":"Problem Statement"},{"location":"problem-statement/#task-1","text":"Performing SAST on the application through GitHub Actions and generate the report. Performing source Code Quality Analysis for linting errors to improve code quality and generate quality report. Generating Software Bill of Materials of application for all dependencies. Setting up GitHub Actions Workflow for DAST. Setting up GitHub Actions Workflow for the Deployment of Application.","title":"Task 1"},{"location":"sbom/","text":"Software Bill of Materials Objective This section aims to generate a Software Bill of Materials for angular-realworld-example-app and generate a report to provide a solution to the 3rd point of the problem statement under Task 1. Software Bill of Materials A software bill of materials is a list of all the open source and third-party components present in a codebase. A software BOM also lists the licenses that govern those components, the versions of the components used in the codebase, and their patch status. With a software bill of materials, we can respond quickly to the security, license, and operational risks that come with open source use. CycloneDX CycloneDX is a tool of lightweight software bill of materials (SBOM) specification designed for use in application security contexts and supply chain component analysis. Angular-realworld-example-app, like most other applications, is built with various dependencies. So I used CycloneDX to generate the SBOM for Angular-realworld-example-app. CycloneDX is available to use a node.js package that can generate SBOMs but also comes in a variety of implementations that can be found here to serve projects which use different stacks such as Auditjs, Python, Maven, .NET, PHP, etc. Generating SBOM through YAML file in GitHub Action I created a new file sbom.yml in the .github/workflows I used this plugin CycloneDX Node.js Generate SBOM I also stored the report in artifacts by using the action actions/upload-artifact@v2 The YAML file is this for generating the SBOM is: name: \"sbom-scan\" on: push: branches: [master] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: install dependencies run: | sudo apt install npm sudo npm install --package-lock npm audit fix - name: Installing SBOM run: | sudo npm install -g @cyclonedx/bom - name: CycloneDX Node.js Generate SBOM uses: CycloneDX/gh-node-module-generatebom@v1.0.0 - name: Archive production artifacts uses: actions/upload-artifact@v2 with: name: sbom report path: | ./bom.xml The report which got generated is here .","title":"Software Bill of Materials"},{"location":"sbom/#software-bill-of-materials","text":"","title":"Software Bill of Materials"},{"location":"sbom/#objective","text":"This section aims to generate a Software Bill of Materials for angular-realworld-example-app and generate a report to provide a solution to the 3rd point of the problem statement under Task 1.","title":"Objective"},{"location":"sbom/#software-bill-of-materials_1","text":"A software bill of materials is a list of all the open source and third-party components present in a codebase. A software BOM also lists the licenses that govern those components, the versions of the components used in the codebase, and their patch status. With a software bill of materials, we can respond quickly to the security, license, and operational risks that come with open source use.","title":"Software Bill of Materials"},{"location":"sbom/#cyclonedx","text":"CycloneDX is a tool of lightweight software bill of materials (SBOM) specification designed for use in application security contexts and supply chain component analysis. Angular-realworld-example-app, like most other applications, is built with various dependencies. So I used CycloneDX to generate the SBOM for Angular-realworld-example-app. CycloneDX is available to use a node.js package that can generate SBOMs but also comes in a variety of implementations that can be found here to serve projects which use different stacks such as Auditjs, Python, Maven, .NET, PHP, etc.","title":"CycloneDX"},{"location":"sbom/#generating-sbom-through-yaml-file-in-github-action","text":"I created a new file sbom.yml in the .github/workflows I used this plugin CycloneDX Node.js Generate SBOM I also stored the report in artifacts by using the action actions/upload-artifact@v2 The YAML file is this for generating the SBOM is: name: \"sbom-scan\" on: push: branches: [master] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: install dependencies run: | sudo apt install npm sudo npm install --package-lock npm audit fix - name: Installing SBOM run: | sudo npm install -g @cyclonedx/bom - name: CycloneDX Node.js Generate SBOM uses: CycloneDX/gh-node-module-generatebom@v1.0.0 - name: Archive production artifacts uses: actions/upload-artifact@v2 with: name: sbom report path: | ./bom.xml The report which got generated is here .","title":"Generating SBOM through YAML file in GitHub Action"}]}